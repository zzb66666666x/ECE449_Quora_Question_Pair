{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "merge_model.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-fBRUHsBQPh"
      },
      "source": [
        "# Model Merge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0UT9MgJBQPn",
        "outputId": "3c3e9060-f1c9-41c7-d7f4-07be65739399"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5lKq9UsBQPn",
        "outputId": "bec1a086-9277-4c94-a1bb-0b56263982aa"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKzFysnMBQPo",
        "outputId": "059b6aa3-e200-4d2b-aaf4-5d4f6003eee2"
      },
      "source": [
        "% cd /content/drive/MyDrive/QuoraQuestionPair"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/QuoraQuestionPair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-EVIlQsBbfm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime, time, json\n",
        "import keras\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from importlib import reload\n",
        "import dev_layers\n",
        "import build_MLP\n",
        "import build_CNN\n",
        "import build_RNN"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95irJciaBcCe"
      },
      "source": [
        "BATCH_SIZE = 1024\n",
        "VALIDATION_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1\n",
        "RNG_SEED = 13371447\n",
        "NB_EPOCHS = 25\n",
        "# files\n",
        "Q1_TRAINING_DATA_FILE = 'q1_train.npy'\n",
        "Q2_TRAINING_DATA_FILE = 'q2_train.npy'\n",
        "Q1_TEST_DATA_FILE = 'q1_test.npy'\n",
        "Q2_TEST_DATA_FILE = 'q2_test.npy'\n",
        "TEST_ID_FILE = 'test_ids.npy'\n",
        "LABEL_TRAINING_DATA_FILE = 'label_train.npy'\n",
        "WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix.npy'\n",
        "NB_WORDS_DATA_FILE = 'nb_words.json'\n",
        "TRAIN_FEAT_NPY_FILE = 'train_feat_array.npy'\n",
        "TEST_FEAT_NPY_FILE = 'test_feat_array.npy'\n",
        "# save params in learning\n",
        "MODEL_WEIGHTS_FILE_RNN = 'RNN_weights.h5'\n",
        "MODEL_WEIGHTS_FILE_CNN = 'CNN_weights.h5'\n",
        "MODEL_WEIGHTS_FILE_MLP = 'MLP_weights.h5'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgLhE3nWBcZz"
      },
      "source": [
        "q1_data = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))\n",
        "q2_data = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))\n",
        "labels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))\n",
        "word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))\n",
        "with open(NB_WORDS_DATA_FILE, 'r') as f:\n",
        "    nb_words = json.load(f)['nb_words']\n",
        "train_feat_array = np.load(open(TRAIN_FEAT_NPY_FILE, 'rb'))\n",
        "test_feat_array = np.load(open(TEST_FEAT_NPY_FILE, 'rb'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrjOL3I1CsYP"
      },
      "source": [
        "X = np.stack((q1_data, q2_data), axis=1)\n",
        "y = labels\n",
        "X_train, X_test, y_train, y_test, X_train_feat, X_test_feat = train_test_split(X, y, train_feat_array, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
        "Q1_train = X_train[:,0]\n",
        "Q2_train = X_train[:,1]\n",
        "Q1_test = X_test[:,0]\n",
        "Q2_test = X_test[:,1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KJuwaC-vaXx",
        "outputId": "35a429f2-3f79-406d-ef57-c76ae6f52da2"
      },
      "source": [
        "train_feat_array.shape, test_feat_array.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404290, 90), (2345796, 90))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OS7eXWGBR3o"
      },
      "source": [
        "## Run Models Individually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTPXVINg8mhM"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB3_CiqSBYF9"
      },
      "source": [
        "model_RNN = build_RNN.get_RNN(word_embedding_matrix, X_train_feat, nb_words)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vdurlFbvocJ",
        "outputId": "7ff75545-5e21-40af-8c54-db18aeae857c"
      },
      "source": [
        "model_RNN.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 30, 300)      36150000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 30, 300)      36150000    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 30, 150)      45150       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 30, 150)      45150       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 30, 150)      406350      time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 30, 150)      406350      time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention (Lambda)              (None, 30, 30)       0           sequential[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 30, 30)       0           attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "soft_alignment_a (Lambda)       (None, 30, 150)      0           attention[0][0]                  \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "soft_alignment_b (Lambda)       (None, 30, 150)      0           permute[0][0]                    \n",
            "                                                                 sequential[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "substract_a (Lambda)            (None, 30, 150)      0           sequential[0][0]                 \n",
            "                                                                 soft_alignment_a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "multiply_a (Lambda)             (None, 30, 150)      0           sequential[0][0]                 \n",
            "                                                                 soft_alignment_a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "substract_b (Lambda)            (None, 30, 150)      0           sequential_1[0][0]               \n",
            "                                                                 soft_alignment_b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "multiply_b (Lambda)             (None, 30, 150)      0           sequential_1[0][0]               \n",
            "                                                                 soft_alignment_b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 30, 600)      0           sequential[0][0]                 \n",
            "                                                                 soft_alignment_a[0][0]           \n",
            "                                                                 substract_a[0][0]                \n",
            "                                                                 multiply_a[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 30, 600)      0           sequential_1[0][0]               \n",
            "                                                                 soft_alignment_b[0][0]           \n",
            "                                                                 substract_b[0][0]                \n",
            "                                                                 multiply_b[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 300)          901200      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 300)          901200      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 600)          0           sequential_2[0][0]               \n",
            "                                                                 sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 150)          90150       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 90)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 150)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          9100        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 150)          600         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 100)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 250)          0           batch_normalization[0][0]        \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 150)          37650       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 150)          0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 150)          600         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 150)          22650       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 150)          0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 150)          600         dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 100)          15100       batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 100)          0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 100)          400         dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 10)           1010        batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 10)           0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 10)           40          dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            11          batch_normalization_4[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 75,183,311\n",
            "Trainable params: 2,882,191\n",
            "Non-trainable params: 72,301,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWCuwQtFvvdL",
        "outputId": "cf2b98da-29ac-4162-f79e-8526da88fcd3"
      },
      "source": [
        "print(\"Starting training at\", datetime.datetime.now())\n",
        "t0 = time.time()\n",
        "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE_RNN, monitor='val_loss', save_best_only=True)]\n",
        "history = model_RNN.fit([Q1_train, Q2_train, X_train_feat],\n",
        "                    y_train,\n",
        "                    epochs=NB_EPOCHS,\n",
        "                    validation_split=VALIDATION_SPLIT,\n",
        "                    verbose=2,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    callbacks=callbacks)\n",
        "t1 = time.time()\n",
        "print(\"Training ended at\", datetime.datetime.now())\n",
        "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training at 2021-05-18 19:24:02.614070\n",
            "Epoch 1/25\n",
            "320/320 - 54s - loss: 0.2101 - accuracy: 0.9104 - val_loss: 0.2409 - val_accuracy: 0.8932\n",
            "Epoch 2/25\n",
            "320/320 - 54s - loss: 0.2077 - accuracy: 0.9118 - val_loss: 0.2358 - val_accuracy: 0.8952\n",
            "Epoch 3/25\n",
            "320/320 - 54s - loss: 0.2047 - accuracy: 0.9128 - val_loss: 0.2367 - val_accuracy: 0.8912\n",
            "Epoch 4/25\n",
            "320/320 - 54s - loss: 0.2030 - accuracy: 0.9141 - val_loss: 0.2418 - val_accuracy: 0.8937\n",
            "Epoch 5/25\n",
            "320/320 - 54s - loss: 0.2006 - accuracy: 0.9155 - val_loss: 0.2408 - val_accuracy: 0.8917\n",
            "Epoch 6/25\n",
            "320/320 - 54s - loss: 0.1990 - accuracy: 0.9156 - val_loss: 0.2407 - val_accuracy: 0.8936\n",
            "Epoch 7/25\n",
            "320/320 - 54s - loss: 0.1969 - accuracy: 0.9171 - val_loss: 0.2408 - val_accuracy: 0.8889\n",
            "Epoch 8/25\n",
            "320/320 - 54s - loss: 0.1947 - accuracy: 0.9183 - val_loss: 0.2382 - val_accuracy: 0.8923\n",
            "Epoch 9/25\n",
            "320/320 - 54s - loss: 0.1912 - accuracy: 0.9197 - val_loss: 0.2473 - val_accuracy: 0.8892\n",
            "Epoch 10/25\n",
            "320/320 - 54s - loss: 0.1901 - accuracy: 0.9199 - val_loss: 0.2509 - val_accuracy: 0.8848\n",
            "Epoch 11/25\n",
            "320/320 - 54s - loss: 0.1868 - accuracy: 0.9221 - val_loss: 0.2488 - val_accuracy: 0.8881\n",
            "Epoch 12/25\n",
            "320/320 - 54s - loss: 0.1860 - accuracy: 0.9224 - val_loss: 0.2492 - val_accuracy: 0.8900\n",
            "Epoch 13/25\n",
            "320/320 - 54s - loss: 0.1838 - accuracy: 0.9233 - val_loss: 0.2528 - val_accuracy: 0.8872\n",
            "Epoch 14/25\n",
            "320/320 - 54s - loss: 0.1810 - accuracy: 0.9251 - val_loss: 0.2500 - val_accuracy: 0.8889\n",
            "Epoch 15/25\n",
            "320/320 - 54s - loss: 0.1788 - accuracy: 0.9257 - val_loss: 0.2581 - val_accuracy: 0.8899\n",
            "Epoch 16/25\n",
            "320/320 - 54s - loss: 0.1770 - accuracy: 0.9268 - val_loss: 0.2492 - val_accuracy: 0.8915\n",
            "Epoch 17/25\n",
            "320/320 - 54s - loss: 0.1749 - accuracy: 0.9275 - val_loss: 0.2539 - val_accuracy: 0.8851\n",
            "Epoch 18/25\n",
            "320/320 - 54s - loss: 0.1736 - accuracy: 0.9291 - val_loss: 0.2681 - val_accuracy: 0.8916\n",
            "Epoch 19/25\n",
            "320/320 - 54s - loss: 0.1713 - accuracy: 0.9290 - val_loss: 0.2512 - val_accuracy: 0.8900\n",
            "Epoch 20/25\n",
            "320/320 - 54s - loss: 0.1695 - accuracy: 0.9303 - val_loss: 0.2674 - val_accuracy: 0.8875\n",
            "Epoch 21/25\n",
            "320/320 - 54s - loss: 0.1676 - accuracy: 0.9309 - val_loss: 0.2614 - val_accuracy: 0.8928\n",
            "Epoch 22/25\n",
            "320/320 - 54s - loss: 0.1658 - accuracy: 0.9321 - val_loss: 0.2532 - val_accuracy: 0.8917\n",
            "Epoch 23/25\n",
            "320/320 - 54s - loss: 0.1631 - accuracy: 0.9334 - val_loss: 0.2572 - val_accuracy: 0.8905\n",
            "Epoch 24/25\n",
            "320/320 - 54s - loss: 0.1617 - accuracy: 0.9336 - val_loss: 0.2622 - val_accuracy: 0.8911\n",
            "Epoch 25/25\n",
            "320/320 - 54s - loss: 0.1612 - accuracy: 0.9345 - val_loss: 0.2716 - val_accuracy: 0.8912\n",
            "Training ended at 2021-05-18 19:46:38.012704\n",
            "Minutes elapsed: 22.589974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bshJuk_F1gsM",
        "outputId": "d4d5b57d-73fd-45ed-d877-5614468f9364"
      },
      "source": [
        "model_RNN.load_weights(MODEL_WEIGHTS_FILE_RNN)\n",
        "loss, accuracy = model_RNN.evaluate([Q1_test, Q2_test, X_test_feat], y_test, verbose=0)\n",
        "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss = 0.2355, accuracy = 0.8969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7X23ckj8jCM"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxvXlztW1Qdk",
        "outputId": "eae42025-2a37-46cb-d2f8-34d272a1a6c5"
      },
      "source": [
        "model_CNN = build_CNN.get_CNN(word_embedding_matrix, X_train_feat, nb_words)\n",
        "model_CNN.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 30, 300)      36150000    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 30, 300)      36150000    input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 30, 150)      45150       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, 30, 150)      45150       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 30, 128)      19328       time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 30, 128)      38528       time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 30, 128)      57728       time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 30, 128)      76928       time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 30, 32)       24032       time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 30, 32)       28832       time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 30, 32)       33632       time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 30, 32)       38432       time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 30, 128)      19328       time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 30, 128)      38528       time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 30, 128)      57728       time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 30, 128)      76928       time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 30, 32)       24032       time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 30, 32)       28832       time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 30, 32)       33632       time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 30, 32)       38432       time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 128)          0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 128)          0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_3 (Glo (None, 128)          0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_4 (Glo (None, 32)           0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_5 (Glo (None, 32)           0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_6 (Glo (None, 32)           0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_7 (Glo (None, 32)           0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_8 (Glo (None, 128)          0           conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_9 (Glo (None, 128)          0           conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_10 (Gl (None, 128)          0           conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_11 (Gl (None, 128)          0           conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_12 (Gl (None, 32)           0           conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_13 (Gl (None, 32)           0           conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_14 (Gl (None, 32)           0           conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_15 (Gl (None, 32)           0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 640)          0           global_average_pooling1d[0][0]   \n",
            "                                                                 global_average_pooling1d_1[0][0] \n",
            "                                                                 global_average_pooling1d_2[0][0] \n",
            "                                                                 global_average_pooling1d_3[0][0] \n",
            "                                                                 global_average_pooling1d_4[0][0] \n",
            "                                                                 global_average_pooling1d_5[0][0] \n",
            "                                                                 global_average_pooling1d_6[0][0] \n",
            "                                                                 global_average_pooling1d_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 640)          0           global_average_pooling1d_8[0][0] \n",
            "                                                                 global_average_pooling1d_9[0][0] \n",
            "                                                                 global_average_pooling1d_10[0][0]\n",
            "                                                                 global_average_pooling1d_11[0][0]\n",
            "                                                                 global_average_pooling1d_12[0][0]\n",
            "                                                                 global_average_pooling1d_13[0][0]\n",
            "                                                                 global_average_pooling1d_14[0][0]\n",
            "                                                                 global_average_pooling1d_15[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 640)          0           concatenate_4[0][0]              \n",
            "                                                                 concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 640)          0           concatenate_4[0][0]              \n",
            "                                                                 concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 1280)         0           lambda[0][0]                     \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 1280)         0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 1280)         5120        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 150)          192150      batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 90)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 150)          0           dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 100)          9100        input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 150)          600         dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100)          0           dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 250)          0           batch_normalization_6[0][0]      \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 100)          25100       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100)          0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100)          400         dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 10)           1010        batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 10)           0           dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10)           40          dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 1)            11          batch_normalization_8[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 73,258,711\n",
            "Trainable params: 955,631\n",
            "Non-trainable params: 72,303,080\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IXOafy83Suj",
        "outputId": "11bee939-9afe-42bf-bbb2-21587d97642f"
      },
      "source": [
        "print(\"Starting training at\", datetime.datetime.now())\n",
        "t0 = time.time()\n",
        "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE_CNN, monitor='val_loss', save_best_only=True)]\n",
        "history = model_CNN.fit([Q1_train, Q2_train, X_train_feat],\n",
        "                    y_train,\n",
        "                    epochs=NB_EPOCHS,\n",
        "                    validation_split=VALIDATION_SPLIT,\n",
        "                    verbose=2,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    callbacks=callbacks)\n",
        "t1 = time.time()\n",
        "print(\"Training ended at\", datetime.datetime.now())\n",
        "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training at 2021-05-18 20:01:00.968299\n",
            "Epoch 1/25\n",
            "320/320 - 28s - loss: 0.4483 - accuracy: 0.7832 - val_loss: 0.3213 - val_accuracy: 0.8600\n",
            "Epoch 2/25\n",
            "320/320 - 22s - loss: 0.3334 - accuracy: 0.8554 - val_loss: 0.2896 - val_accuracy: 0.8693\n",
            "Epoch 3/25\n",
            "320/320 - 22s - loss: 0.3072 - accuracy: 0.8640 - val_loss: 0.2754 - val_accuracy: 0.8756\n",
            "Epoch 4/25\n",
            "320/320 - 22s - loss: 0.2916 - accuracy: 0.8698 - val_loss: 0.2657 - val_accuracy: 0.8789\n",
            "Epoch 5/25\n",
            "320/320 - 22s - loss: 0.2806 - accuracy: 0.8750 - val_loss: 0.2589 - val_accuracy: 0.8813\n",
            "Epoch 6/25\n",
            "320/320 - 22s - loss: 0.2695 - accuracy: 0.8801 - val_loss: 0.2524 - val_accuracy: 0.8853\n",
            "Epoch 7/25\n",
            "320/320 - 22s - loss: 0.2603 - accuracy: 0.8854 - val_loss: 0.2479 - val_accuracy: 0.8875\n",
            "Epoch 8/25\n",
            "320/320 - 22s - loss: 0.2507 - accuracy: 0.8899 - val_loss: 0.2464 - val_accuracy: 0.8872\n",
            "Epoch 9/25\n",
            "320/320 - 22s - loss: 0.2413 - accuracy: 0.8949 - val_loss: 0.2455 - val_accuracy: 0.8893\n",
            "Epoch 10/25\n",
            "320/320 - 22s - loss: 0.2329 - accuracy: 0.8986 - val_loss: 0.2414 - val_accuracy: 0.8899\n",
            "Epoch 11/25\n",
            "320/320 - 22s - loss: 0.2240 - accuracy: 0.9036 - val_loss: 0.2455 - val_accuracy: 0.8892\n",
            "Epoch 12/25\n",
            "320/320 - 22s - loss: 0.2146 - accuracy: 0.9082 - val_loss: 0.2415 - val_accuracy: 0.8920\n",
            "Epoch 13/25\n",
            "320/320 - 22s - loss: 0.2053 - accuracy: 0.9131 - val_loss: 0.2403 - val_accuracy: 0.8912\n",
            "Epoch 14/25\n",
            "320/320 - 22s - loss: 0.1968 - accuracy: 0.9175 - val_loss: 0.2425 - val_accuracy: 0.8920\n",
            "Epoch 15/25\n",
            "320/320 - 22s - loss: 0.1882 - accuracy: 0.9222 - val_loss: 0.2481 - val_accuracy: 0.8903\n",
            "Epoch 16/25\n",
            "320/320 - 22s - loss: 0.1801 - accuracy: 0.9268 - val_loss: 0.2495 - val_accuracy: 0.8914\n",
            "Epoch 17/25\n",
            "320/320 - 22s - loss: 0.1721 - accuracy: 0.9298 - val_loss: 0.2557 - val_accuracy: 0.8908\n",
            "Epoch 18/25\n",
            "320/320 - 22s - loss: 0.1638 - accuracy: 0.9345 - val_loss: 0.2573 - val_accuracy: 0.8917\n",
            "Epoch 19/25\n",
            "320/320 - 22s - loss: 0.1556 - accuracy: 0.9380 - val_loss: 0.2617 - val_accuracy: 0.8911\n",
            "Epoch 20/25\n",
            "320/320 - 22s - loss: 0.1498 - accuracy: 0.9412 - val_loss: 0.2688 - val_accuracy: 0.8916\n",
            "Epoch 21/25\n",
            "320/320 - 22s - loss: 0.1425 - accuracy: 0.9443 - val_loss: 0.2741 - val_accuracy: 0.8906\n",
            "Epoch 22/25\n",
            "320/320 - 22s - loss: 0.1366 - accuracy: 0.9471 - val_loss: 0.2824 - val_accuracy: 0.8910\n",
            "Epoch 23/25\n",
            "320/320 - 22s - loss: 0.1302 - accuracy: 0.9497 - val_loss: 0.2868 - val_accuracy: 0.8892\n",
            "Epoch 24/25\n",
            "320/320 - 22s - loss: 0.1244 - accuracy: 0.9528 - val_loss: 0.2864 - val_accuracy: 0.8922\n",
            "Epoch 25/25\n",
            "320/320 - 22s - loss: 0.1188 - accuracy: 0.9552 - val_loss: 0.3023 - val_accuracy: 0.8904\n",
            "Training ended at 2021-05-18 20:10:34.541289\n",
            "Minutes elapsed: 9.559547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ3JLLiu6MiF",
        "outputId": "f7fba3ff-4df3-4121-9e72-e107d505be3c"
      },
      "source": [
        "model_CNN.load_weights(MODEL_WEIGHTS_FILE_CNN)\n",
        "loss, accuracy = model_CNN.evaluate([Q1_test, Q2_test, X_test_feat], y_test, verbose=0)\n",
        "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss = 0.2411, accuracy = 0.8917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpGpR1oM8e6j"
      },
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ucEqC-h78l1",
        "outputId": "97c80b88-1fba-4b18-cf25-0c14b17549ea"
      },
      "source": [
        "model_MLP = build_MLP.get_MLP(word_embedding_matrix, X_train_feat, nb_words)\n",
        "model_MLP.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 30, 300)      36150000    input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 30, 300)      36150000    input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistrib (None, 30, 300)      90300       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_9 (TimeDistrib (None, 30, 300)      90300       embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 300)          0           time_distributed_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 300)          0           time_distributed_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 600)          0           lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 200)          120200      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 90)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 200)          0           dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 100)          9100        input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 200)          800         dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 100)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 300)          0           batch_normalization_9[0][0]      \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 200)          60200       concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 200)          0           dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 200)          800         dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 200)          40200       batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 200)          0           dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 200)          800         dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 200)          40200       batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 200)          0           dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 200)          800         dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 1)            201         batch_normalization_12[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 72,753,901\n",
            "Trainable params: 452,301\n",
            "Non-trainable params: 72,301,600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s55gGAeM8Gsm",
        "outputId": "81897658-3277-454e-d40c-0e80b53d0662"
      },
      "source": [
        "print(\"Starting training at\", datetime.datetime.now())\n",
        "t0 = time.time()\n",
        "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE_MLP, monitor='val_loss', save_best_only=True)]\n",
        "history = model_MLP.fit([Q1_train, Q2_train, X_train_feat],\n",
        "                    y_train,\n",
        "                    epochs=NB_EPOCHS,\n",
        "                    validation_split=VALIDATION_SPLIT,\n",
        "                    verbose=2,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    callbacks=callbacks)\n",
        "t1 = time.time()\n",
        "print(\"Training ended at\", datetime.datetime.now())\n",
        "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training at 2021-05-18 19:48:29.469683\n",
            "Epoch 1/25\n",
            "320/320 - 8s - loss: 0.3181 - accuracy: 0.8450 - val_loss: 0.2651 - val_accuracy: 0.8720\n",
            "Epoch 2/25\n",
            "320/320 - 6s - loss: 0.2664 - accuracy: 0.8718 - val_loss: 0.2570 - val_accuracy: 0.8756\n",
            "Epoch 3/25\n",
            "320/320 - 6s - loss: 0.2502 - accuracy: 0.8807 - val_loss: 0.2453 - val_accuracy: 0.8832\n",
            "Epoch 4/25\n",
            "320/320 - 6s - loss: 0.2380 - accuracy: 0.8883 - val_loss: 0.2583 - val_accuracy: 0.8748\n",
            "Epoch 5/25\n",
            "320/320 - 6s - loss: 0.2272 - accuracy: 0.8945 - val_loss: 0.2508 - val_accuracy: 0.8819\n",
            "Epoch 6/25\n",
            "320/320 - 6s - loss: 0.2168 - accuracy: 0.8999 - val_loss: 0.2334 - val_accuracy: 0.8889\n",
            "Epoch 7/25\n",
            "320/320 - 6s - loss: 0.2074 - accuracy: 0.9054 - val_loss: 0.2426 - val_accuracy: 0.8858\n",
            "Epoch 8/25\n",
            "320/320 - 6s - loss: 0.1978 - accuracy: 0.9105 - val_loss: 0.2442 - val_accuracy: 0.8836\n",
            "Epoch 9/25\n",
            "320/320 - 6s - loss: 0.1887 - accuracy: 0.9151 - val_loss: 0.2430 - val_accuracy: 0.8878\n",
            "Epoch 10/25\n",
            "320/320 - 6s - loss: 0.1792 - accuracy: 0.9201 - val_loss: 0.2425 - val_accuracy: 0.8913\n",
            "Epoch 11/25\n",
            "320/320 - 6s - loss: 0.1712 - accuracy: 0.9244 - val_loss: 0.2533 - val_accuracy: 0.8869\n",
            "Epoch 12/25\n",
            "320/320 - 6s - loss: 0.1624 - accuracy: 0.9285 - val_loss: 0.2599 - val_accuracy: 0.8908\n",
            "Epoch 13/25\n",
            "320/320 - 6s - loss: 0.1535 - accuracy: 0.9332 - val_loss: 0.2684 - val_accuracy: 0.8898\n",
            "Epoch 14/25\n",
            "320/320 - 6s - loss: 0.1475 - accuracy: 0.9363 - val_loss: 0.2641 - val_accuracy: 0.8823\n",
            "Epoch 15/25\n",
            "320/320 - 6s - loss: 0.1416 - accuracy: 0.9392 - val_loss: 0.2798 - val_accuracy: 0.8874\n",
            "Epoch 16/25\n",
            "320/320 - 6s - loss: 0.1339 - accuracy: 0.9424 - val_loss: 0.2812 - val_accuracy: 0.8859\n",
            "Epoch 17/25\n",
            "320/320 - 6s - loss: 0.1277 - accuracy: 0.9455 - val_loss: 0.3065 - val_accuracy: 0.8847\n",
            "Epoch 18/25\n",
            "320/320 - 6s - loss: 0.1234 - accuracy: 0.9476 - val_loss: 0.3210 - val_accuracy: 0.8856\n",
            "Epoch 19/25\n",
            "320/320 - 6s - loss: 0.1189 - accuracy: 0.9499 - val_loss: 0.3050 - val_accuracy: 0.8816\n",
            "Epoch 20/25\n",
            "320/320 - 6s - loss: 0.1138 - accuracy: 0.9521 - val_loss: 0.3475 - val_accuracy: 0.8838\n",
            "Epoch 21/25\n",
            "320/320 - 6s - loss: 0.1093 - accuracy: 0.9541 - val_loss: 0.3425 - val_accuracy: 0.8862\n",
            "Epoch 22/25\n",
            "320/320 - 6s - loss: 0.1052 - accuracy: 0.9563 - val_loss: 0.3263 - val_accuracy: 0.8854\n",
            "Epoch 23/25\n",
            "320/320 - 6s - loss: 0.1038 - accuracy: 0.9563 - val_loss: 0.3416 - val_accuracy: 0.8873\n",
            "Epoch 24/25\n",
            "320/320 - 6s - loss: 0.1005 - accuracy: 0.9581 - val_loss: 0.3690 - val_accuracy: 0.8865\n",
            "Epoch 25/25\n",
            "320/320 - 6s - loss: 0.0962 - accuracy: 0.9600 - val_loss: 0.3659 - val_accuracy: 0.8845\n",
            "Training ended at 2021-05-18 19:51:14.302455\n",
            "Minutes elapsed: 2.747205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5SmnzDA8Vt6",
        "outputId": "8040fea3-84a0-415a-e415-3e7fb7a42530"
      },
      "source": [
        "model_MLP.load_weights(MODEL_WEIGHTS_FILE_MLP)\n",
        "loss, accuracy = model_MLP.evaluate([Q1_test, Q2_test, X_test_feat], y_test, verbose=0)\n",
        "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss = 0.2353, accuracy = 0.8884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmL20TJgHZJc"
      },
      "source": [
        "## Make Submissions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlXdfAPtHoHF"
      },
      "source": [
        "q1_test_data = np.load(open(Q1_TEST_DATA_FILE, 'rb'))\n",
        "q2_test_data = np.load(open(Q2_TEST_DATA_FILE, 'rb'))\n",
        "test_ids = np.load(open(TEST_ID_FILE, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nV6TFOGHu3c"
      },
      "source": [
        "test_predict = model_RNN.predict((q1_test_data, q2_test_data, test_feat_array), batch_size=BATCH_SIZE).reshape(-1,)\n",
        "test_predict += model_RNN.predict((q2_test_data, q1_test_data, test_feat_array), batch_size=BATCH_SIZE).reshape(-1,)\n",
        "test_predict /= 2\n",
        "\n",
        "res_df=pd.DataFrame({'test_id':test_ids, 'is_duplicate':test_predict.ravel()})\n",
        "res_df.to_csv('./out_all_RNN_feature.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEsqK6UjH0rK"
      },
      "source": [
        "test_predict = model_CNN.predict((q1_test_data, q2_test_data, test_feat_array), batch_size=BATCH_SIZE).reshape(-1,)\n",
        "test_predict += model_CNN.predict((q2_test_data, q1_test_data, test_feat_array), batch_size=BATCH_SIZE).reshape(-1,)\n",
        "test_predict /= 2\n",
        "\n",
        "res_df=pd.DataFrame({'test_id':test_ids, 'is_duplicate':test_predict.ravel()})\n",
        "res_df.to_csv('./out_all_CNN_feature.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRGzH139H1Rf"
      },
      "source": [
        "test_predict = model_MLP.predict((q1_test_data, q2_test_data, test_feat_array), batch_size=BATCH_SIZE).reshape(-1,)\n",
        "test_predict += model_MLP.predict((q2_test_data, q1_test_data, test_feat_array), batch_size=BATCH_SIZE).reshape(-1,)\n",
        "test_predict /= 2\n",
        "\n",
        "res_df=pd.DataFrame({'test_id':test_ids, 'is_duplicate':test_predict.ravel()})\n",
        "res_df.to_csv('./out_all_MLP_feature.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHTZNeA0Djub"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmaEISG5Tksd"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpGWi1vQTjbD"
      },
      "source": [
        "model_RNN.save(\"RNN_model.h5\")\n",
        "model_MLP.save(\"MLP_model.h5\")\n",
        "model_CNN.save(\"CNN_model.h5\")"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}