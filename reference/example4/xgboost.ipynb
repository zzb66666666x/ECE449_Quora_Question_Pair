{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Models\n",
    "Initially single xgb model was created, finally 7 LSTM models were created with random dense layers and dropouts and averaged with 6 xgb models with random hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alibaba/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import functools\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Features\n",
    "Features were created using feature_engineering.ipynb and page_rank.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 79), (2345796, 79))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=4242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UpDown Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.189752932122\n"
     ]
    }
   ],
   "source": [
    "#UPDownSampling\n",
    "pos_train = X_train[y_train == 1]\n",
    "neg_train = X_train[y_train == 0]\n",
    "X_train = pd.concat((neg_train, pos_train.iloc[:int(0.8*len(pos_train))], neg_train))\n",
    "y_train = np.array([0] * neg_train.shape[0] + [1] * pos_train.iloc[:int(0.8*len(pos_train))].shape[0] + [0] * neg_train.shape[0])\n",
    "print(np.mean(y_train))\n",
    "del pos_train, neg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.189234677675\n"
     ]
    }
   ],
   "source": [
    "pos_valid = X_valid[y_valid == 1]\n",
    "neg_valid = X_valid[y_valid == 0]\n",
    "X_valid = pd.concat((neg_valid, pos_valid.iloc[:int(0.8 * len(pos_valid))], neg_valid))\n",
    "y_valid = np.array([0] * neg_valid.shape[0] + [1] * pos_valid.iloc[:int(0.8 * len(pos_valid))].shape[0] + [0] * neg_valid.shape[0])\n",
    "print(np.mean(y_valid))\n",
    "del pos_valid, neg_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lots of XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('xgb_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for fold = 3\n",
      "[0]\ttrain-logloss:0.481289\tvalid-logloss:0.4806\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.354035\tvalid-logloss:0.35419\n",
      "[100]\ttrain-logloss:0.295429\tvalid-logloss:0.295922\n",
      "[150]\ttrain-logloss:0.264295\tvalid-logloss:0.265022\n",
      "[200]\ttrain-logloss:0.24581\tvalid-logloss:0.246716\n",
      "[250]\ttrain-logloss:0.233024\tvalid-logloss:0.234021\n",
      "[300]\ttrain-logloss:0.224399\tvalid-logloss:0.225483\n",
      "[350]\ttrain-logloss:0.218405\tvalid-logloss:0.21954\n",
      "[400]\ttrain-logloss:0.21409\tvalid-logloss:0.215287\n",
      "[450]\ttrain-logloss:0.210928\tvalid-logloss:0.21218\n",
      "[500]\ttrain-logloss:0.208236\tvalid-logloss:0.209555\n",
      "[550]\ttrain-logloss:0.20598\tvalid-logloss:0.20737\n",
      "[600]\ttrain-logloss:0.203961\tvalid-logloss:0.205427\n",
      "[650]\ttrain-logloss:0.20218\tvalid-logloss:0.203758\n",
      "[700]\ttrain-logloss:0.200623\tvalid-logloss:0.20231\n",
      "[750]\ttrain-logloss:0.199224\tvalid-logloss:0.201009\n",
      "[800]\ttrain-logloss:0.197967\tvalid-logloss:0.199835\n",
      "[850]\ttrain-logloss:0.19684\tvalid-logloss:0.198806\n",
      "[900]\ttrain-logloss:0.195795\tvalid-logloss:0.197856\n",
      "[950]\ttrain-logloss:0.194886\tvalid-logloss:0.197039\n",
      "[1000]\ttrain-logloss:0.194034\tvalid-logloss:0.19626\n",
      "[1050]\ttrain-logloss:0.193199\tvalid-logloss:0.195516\n",
      "[1100]\ttrain-logloss:0.192444\tvalid-logloss:0.19482\n",
      "[1150]\ttrain-logloss:0.191738\tvalid-logloss:0.194204\n",
      "[1200]\ttrain-logloss:0.191059\tvalid-logloss:0.193607\n",
      "[1250]\ttrain-logloss:0.190502\tvalid-logloss:0.193132\n",
      "[1300]\ttrain-logloss:0.189888\tvalid-logloss:0.192601\n",
      "[1350]\ttrain-logloss:0.189353\tvalid-logloss:0.192148\n",
      "[1400]\ttrain-logloss:0.188828\tvalid-logloss:0.191703\n",
      "[1450]\ttrain-logloss:0.188332\tvalid-logloss:0.191297\n",
      "[1500]\ttrain-logloss:0.187865\tvalid-logloss:0.190909\n",
      "[1550]\ttrain-logloss:0.187361\tvalid-logloss:0.190503\n",
      "[1600]\ttrain-logloss:0.186907\tvalid-logloss:0.190122\n",
      "[1650]\ttrain-logloss:0.186463\tvalid-logloss:0.189761\n",
      "[1700]\ttrain-logloss:0.186063\tvalid-logloss:0.189457\n",
      "[1750]\ttrain-logloss:0.185684\tvalid-logloss:0.189182\n",
      "[1800]\ttrain-logloss:0.185306\tvalid-logloss:0.1889\n",
      "[1850]\ttrain-logloss:0.184945\tvalid-logloss:0.18861\n",
      "[1900]\ttrain-logloss:0.184614\tvalid-logloss:0.188362\n",
      "[1950]\ttrain-logloss:0.184249\tvalid-logloss:0.188078\n",
      "[2000]\ttrain-logloss:0.18394\tvalid-logloss:0.187851\n",
      "[2050]\ttrain-logloss:0.18363\tvalid-logloss:0.187627\n",
      "[2100]\ttrain-logloss:0.183317\tvalid-logloss:0.187397\n",
      "[2150]\ttrain-logloss:0.183003\tvalid-logloss:0.18716\n",
      "[2200]\ttrain-logloss:0.182683\tvalid-logloss:0.186939\n",
      "[2250]\ttrain-logloss:0.182407\tvalid-logloss:0.186757\n",
      "[2300]\ttrain-logloss:0.182136\tvalid-logloss:0.186562\n",
      "[2350]\ttrain-logloss:0.18186\tvalid-logloss:0.186356\n",
      "[2400]\ttrain-logloss:0.181606\tvalid-logloss:0.186187\n",
      "[2450]\ttrain-logloss:0.181347\tvalid-logloss:0.18601\n",
      "-> predicting\n",
      "saving to csv\n",
      "training for fold = 4\n",
      "[0]\ttrain-logloss:0.480928\tvalid-logloss:0.480253\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.343298\tvalid-logloss:0.343896\n",
      "[100]\ttrain-logloss:0.281703\tvalid-logloss:0.282902\n",
      "[150]\ttrain-logloss:0.249024\tvalid-logloss:0.250733\n",
      "[200]\ttrain-logloss:0.229874\tvalid-logloss:0.231962\n",
      "[250]\ttrain-logloss:0.217226\tvalid-logloss:0.219652\n",
      "[300]\ttrain-logloss:0.20907\tvalid-logloss:0.211827\n",
      "[350]\ttrain-logloss:0.203542\tvalid-logloss:0.206526\n",
      "[400]\ttrain-logloss:0.199622\tvalid-logloss:0.202825\n",
      "[450]\ttrain-logloss:0.196582\tvalid-logloss:0.199971\n",
      "[500]\ttrain-logloss:0.194132\tvalid-logloss:0.197762\n",
      "[550]\ttrain-logloss:0.192002\tvalid-logloss:0.195874\n",
      "[600]\ttrain-logloss:0.190061\tvalid-logloss:0.194207\n",
      "[650]\ttrain-logloss:0.188298\tvalid-logloss:0.192746\n",
      "[700]\ttrain-logloss:0.186672\tvalid-logloss:0.191454\n",
      "[750]\ttrain-logloss:0.185277\tvalid-logloss:0.190356\n",
      "[800]\ttrain-logloss:0.183948\tvalid-logloss:0.189351\n",
      "[850]\ttrain-logloss:0.182796\tvalid-logloss:0.188493\n",
      "[900]\ttrain-logloss:0.181699\tvalid-logloss:0.187707\n",
      "[950]\ttrain-logloss:0.180706\tvalid-logloss:0.187003\n",
      "[1000]\ttrain-logloss:0.179803\tvalid-logloss:0.186418\n",
      "[1050]\ttrain-logloss:0.178919\tvalid-logloss:0.185857\n",
      "[1100]\ttrain-logloss:0.178108\tvalid-logloss:0.185379\n",
      "[1150]\ttrain-logloss:0.177307\tvalid-logloss:0.184929\n",
      "[1200]\ttrain-logloss:0.176604\tvalid-logloss:0.184494\n",
      "[1250]\ttrain-logloss:0.175916\tvalid-logloss:0.184111\n",
      "[1300]\ttrain-logloss:0.175244\tvalid-logloss:0.183754\n",
      "[1350]\ttrain-logloss:0.174547\tvalid-logloss:0.183369\n",
      "[1400]\ttrain-logloss:0.17391\tvalid-logloss:0.183036\n",
      "[1450]\ttrain-logloss:0.173343\tvalid-logloss:0.182769\n",
      "[1500]\ttrain-logloss:0.172736\tvalid-logloss:0.182482\n",
      "[1550]\ttrain-logloss:0.172143\tvalid-logloss:0.182193\n",
      "[1600]\ttrain-logloss:0.171617\tvalid-logloss:0.181973\n",
      "[1650]\ttrain-logloss:0.171092\tvalid-logloss:0.181748\n",
      "[1700]\ttrain-logloss:0.17057\tvalid-logloss:0.181542\n",
      "[1750]\ttrain-logloss:0.170064\tvalid-logloss:0.181342\n",
      "[1800]\ttrain-logloss:0.169515\tvalid-logloss:0.181119\n",
      "[1850]\ttrain-logloss:0.169044\tvalid-logloss:0.180929\n",
      "[1900]\ttrain-logloss:0.168593\tvalid-logloss:0.180761\n",
      "[1950]\ttrain-logloss:0.168131\tvalid-logloss:0.180596\n",
      "[2000]\ttrain-logloss:0.167665\tvalid-logloss:0.18042\n",
      "[2050]\ttrain-logloss:0.167196\tvalid-logloss:0.18024\n",
      "[2100]\ttrain-logloss:0.166766\tvalid-logloss:0.180115\n",
      "[2150]\ttrain-logloss:0.166319\tvalid-logloss:0.179945\n",
      "[2200]\ttrain-logloss:0.165884\tvalid-logloss:0.179818\n",
      "[2250]\ttrain-logloss:0.165463\tvalid-logloss:0.179687\n",
      "[2300]\ttrain-logloss:0.165052\tvalid-logloss:0.179571\n",
      "[2350]\ttrain-logloss:0.164625\tvalid-logloss:0.179437\n",
      "[2400]\ttrain-logloss:0.164221\tvalid-logloss:0.179332\n",
      "[2450]\ttrain-logloss:0.163809\tvalid-logloss:0.179224\n",
      "-> predicting\n",
      "saving to csv\n",
      "training for fold = 5\n",
      "[0]\ttrain-logloss:0.478314\tvalid-logloss:0.47766\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-dc6e4fe93b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'training for fold = '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'-> predicting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0md_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alibaba/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alibaba/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alibaba/anaconda2/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    np.random.seed(i+1)\n",
    "    params = {}\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    et = [.02,.025,.01,.015]\n",
    "    params['eta'] = np.random.choice(et)\n",
    "    params['n_jobs'] = 5\n",
    "    depth = [4,5,6,7]\n",
    "    params['max_depth'] = np.random.choice(depth)\n",
    "    sub = [.5,.6,.7,.4]\n",
    "    params['subsample'] = np.random.choice(sub)\n",
    "    params['base_score'] = 0.2\n",
    "    col = [1,.7]\n",
    "    params['colsample_bytree'] = np.random.choice(col)\n",
    "    #params['scale_pos_weight'] = 0.36\n",
    "\n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    print ('training for fold = '+ str(i+1))\n",
    "    bst = xgb.train(params, d_train, 2500, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "    print ('-> predicting')\n",
    "    d_test = xgb.DMatrix(X_test)\n",
    "    p_test = bst.predict(d_test, ntree_limit=bst.best_ntree_limit)\n",
    "    print('saving to csv')\n",
    "    sub = pd.read_csv('xgb_final.csv')\n",
    "    sub[str('fold'+ str(i+1))] = p_test\n",
    "    sub.to_csv('xgb_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    params = {}\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    params['eta'] = 0.02\n",
    "    params['n_jobs'] = 5\n",
    "    params['max_depth'] = 6\n",
    "    params['subsample'] = 0.6\n",
    "    params['base_score'] = 0.2\n",
    "    #params['scale_pos_weight'] = 0.36\n",
    "\n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.717087\tvalid-logloss:0.716136\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.401809\tvalid-logloss:0.40393\n",
      "[100]\ttrain-logloss:0.330451\tvalid-logloss:0.334219\n",
      "[150]\ttrain-logloss:0.30513\tvalid-logloss:0.309944\n",
      "[200]\ttrain-logloss:0.293646\tvalid-logloss:0.299264\n",
      "[250]\ttrain-logloss:0.286529\tvalid-logloss:0.293\n",
      "[300]\ttrain-logloss:0.280016\tvalid-logloss:0.28747\n",
      "[350]\ttrain-logloss:0.274416\tvalid-logloss:0.283213\n",
      "[400]\ttrain-logloss:0.269995\tvalid-logloss:0.280187\n",
      "[450]\ttrain-logloss:0.266099\tvalid-logloss:0.277612\n",
      "[500]\ttrain-logloss:0.262861\tvalid-logloss:0.275592\n",
      "[550]\ttrain-logloss:0.259844\tvalid-logloss:0.273687\n",
      "[600]\ttrain-logloss:0.257057\tvalid-logloss:0.27208\n",
      "[650]\ttrain-logloss:0.254442\tvalid-logloss:0.270704\n",
      "[700]\ttrain-logloss:0.252072\tvalid-logloss:0.269568\n",
      "[750]\ttrain-logloss:0.250111\tvalid-logloss:0.268627\n",
      "[800]\ttrain-logloss:0.248044\tvalid-logloss:0.26775\n",
      "[850]\ttrain-logloss:0.246078\tvalid-logloss:0.266864\n",
      "[900]\ttrain-logloss:0.244128\tvalid-logloss:0.266068\n",
      "[950]\ttrain-logloss:0.242446\tvalid-logloss:0.265432\n",
      "[1000]\ttrain-logloss:0.240794\tvalid-logloss:0.26476\n",
      "[1050]\ttrain-logloss:0.239292\tvalid-logloss:0.264284\n",
      "[1100]\ttrain-logloss:0.237621\tvalid-logloss:0.263672\n",
      "[1150]\ttrain-logloss:0.236114\tvalid-logloss:0.263176\n",
      "[1200]\ttrain-logloss:0.23448\tvalid-logloss:0.262573\n",
      "[1250]\ttrain-logloss:0.232799\tvalid-logloss:0.261975\n",
      "[1300]\ttrain-logloss:0.231246\tvalid-logloss:0.261541\n",
      "[1350]\ttrain-logloss:0.229752\tvalid-logloss:0.261112\n",
      "[1400]\ttrain-logloss:0.228371\tvalid-logloss:0.260741\n",
      "[1450]\ttrain-logloss:0.226774\tvalid-logloss:0.260212\n",
      "[1500]\ttrain-logloss:0.22535\tvalid-logloss:0.259775\n",
      "[1550]\ttrain-logloss:0.223974\tvalid-logloss:0.259414\n",
      "[1600]\ttrain-logloss:0.222624\tvalid-logloss:0.259031\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-5b6b59116c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alibaba/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alibaba/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alibaba/anaconda2/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bst = xgb.train(params, d_train, 2500, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "print(log_loss(y_valid, bst.predict(d_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(X_test)\n",
    "p_test = bst.predict(d_test, ntree_limit=bst.best_ntree_limit)\n",
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = test_ids\n",
    "sub['is_duplicate'] = p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.163087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.202292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.067887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.000103\n",
       "1        1      0.163087\n",
       "2        2      0.202292\n",
       "3        3      0.000119\n",
       "4        4      0.067887"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: sub_xgb_1.csv (deflated 59%)\n"
     ]
    }
   ],
   "source": [
    "sub.to_csv('sub_xgb_1.csv',index = False)\n",
    "! rm -rf test.zip\n",
    "! zip -r test_try.zip sub_xgb_1.csv"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
