Model: "model_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            [(None, 30)]         0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            [(None, 30)]         0                                            
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 30, 300)      36150000    input_7[0][0]                    
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 30, 300)      36150000    input_8[0][0]                    
__________________________________________________________________________________________________
time_distributed_30 (TimeDistri (None, 30, 200)      60200       embedding_6[0][0]                
__________________________________________________________________________________________________
time_distributed_31 (TimeDistri (None, 30, 200)      60200       embedding_7[0][0]                
__________________________________________________________________________________________________
sequential_15 (Sequential)      (None, 30, 200)      721800      time_distributed_30[0][0]        
__________________________________________________________________________________________________
sequential_16 (Sequential)      (None, 30, 200)      721800      time_distributed_31[0][0]        
__________________________________________________________________________________________________
attention (Lambda)              (None, 30, 30)       0           sequential_15[0][0]              
                                                                 sequential_16[0][0]              
__________________________________________________________________________________________________
permute_3 (Permute)             (None, 30, 30)       0           attention[0][0]                  
__________________________________________________________________________________________________
soft_alignment_a (Lambda)       (None, 30, 200)      0           attention[0][0]                  
                                                                 sequential_16[0][0]              
__________________________________________________________________________________________________
soft_alignment_b (Lambda)       (None, 30, 200)      0           permute_3[0][0]                  
                                                                 sequential_15[0][0]              
__________________________________________________________________________________________________
substract_a (Lambda)            (None, 30, 200)      0           sequential_15[0][0]              
                                                                 soft_alignment_a[0][0]           
__________________________________________________________________________________________________
multiply_a (Lambda)             (None, 30, 200)      0           sequential_15[0][0]              
                                                                 soft_alignment_a[0][0]           
__________________________________________________________________________________________________
substract_b (Lambda)            (None, 30, 200)      0           sequential_16[0][0]              
                                                                 soft_alignment_b[0][0]           
__________________________________________________________________________________________________
multiply_b (Lambda)             (None, 30, 200)      0           sequential_16[0][0]              
                                                                 soft_alignment_b[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 30, 800)      0           sequential_15[0][0]              
                                                                 soft_alignment_a[0][0]           
                                                                 substract_a[0][0]                
                                                                 multiply_a[0][0]                 
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 30, 800)      0           sequential_16[0][0]              
                                                                 soft_alignment_b[0][0]           
                                                                 substract_b[0][0]                
                                                                 multiply_b[0][0]                 
__________________________________________________________________________________________________
sequential_17 (Sequential)      (None, 30, 200)      1681800     concatenate_9[0][0]              
__________________________________________________________________________________________________
sequential_18 (Sequential)      (None, 30, 200)      1681800     concatenate_10[0][0]             
__________________________________________________________________________________________________
global_average_pooling1d_6 (Glo (None, 200)          0           sequential_17[0][0]              
__________________________________________________________________________________________________
global_max_pooling1d_6 (GlobalM (None, 200)          0           sequential_17[0][0]              
__________________________________________________________________________________________________
global_average_pooling1d_7 (Glo (None, 200)          0           sequential_18[0][0]              
__________________________________________________________________________________________________
global_max_pooling1d_7 (GlobalM (None, 200)          0           sequential_18[0][0]              
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 800)          0           global_average_pooling1d_6[0][0] 
                                                                 global_max_pooling1d_6[0][0]     
                                                                 global_average_pooling1d_7[0][0] 
                                                                 global_max_pooling1d_7[0][0]     
__________________________________________________________________________________________________
sequential_19 (Sequential)      (None, 300)          241500      concatenate_11[0][0]             
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 100)          30100       sequential_19[0][0]              
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 100)          0           dense_38[0][0]                   
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 100)          400         dropout_27[0][0]                 
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 10)           1010        batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 10)           0           dense_39[0][0]                   
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 10)           40          dropout_28[0][0]                 
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 1)            11          batch_normalization_12[0][0]     
==================================================================================================
Total params: 77,500,661
Trainable params: 5,199,841
Non-trainable params: 72,300,820


Starting training at 2021-05-16 10:21:41.501995
Epoch 1/25
320/320 - 93s - loss: 0.5970 - accuracy: 0.6910 - val_loss: 0.5749 - val_accuracy: 0.7200
Epoch 2/25
320/320 - 77s - loss: 0.5145 - accuracy: 0.7431 - val_loss: 0.4793 - val_accuracy: 0.7602
Epoch 3/25
320/320 - 77s - loss: 0.4854 - accuracy: 0.7602 - val_loss: 0.4734 - val_accuracy: 0.7616
Epoch 4/25
320/320 - 76s - loss: 0.4673 - accuracy: 0.7707 - val_loss: 0.4463 - val_accuracy: 0.7813
Epoch 5/25
320/320 - 77s - loss: 0.4524 - accuracy: 0.7809 - val_loss: 0.4597 - val_accuracy: 0.7738
Epoch 6/25
320/320 - 77s - loss: 0.4396 - accuracy: 0.7887 - val_loss: 0.4436 - val_accuracy: 0.7844
Epoch 7/25
320/320 - 77s - loss: 0.4279 - accuracy: 0.7963 - val_loss: 0.4350 - val_accuracy: 0.7923
Epoch 8/25
320/320 - 76s - loss: 0.4163 - accuracy: 0.8034 - val_loss: 0.4221 - val_accuracy: 0.7952
Epoch 9/25
320/320 - 77s - loss: 0.4048 - accuracy: 0.8109 - val_loss: 0.4119 - val_accuracy: 0.8009
Epoch 10/25
320/320 - 77s - loss: 0.3952 - accuracy: 0.8169 - val_loss: 0.4045 - val_accuracy: 0.8057
Epoch 11/25
320/320 - 77s - loss: 0.3853 - accuracy: 0.8218 - val_loss: 0.3989 - val_accuracy: 0.8078
Epoch 12/25
320/320 - 77s - loss: 0.3761 - accuracy: 0.8275 - val_loss: 0.3974 - val_accuracy: 0.8107
Epoch 13/25
320/320 - 76s - loss: 0.3678 - accuracy: 0.8323 - val_loss: 0.3922 - val_accuracy: 0.8156
Epoch 14/25
320/320 - 76s - loss: 0.3584 - accuracy: 0.8373 - val_loss: 0.3926 - val_accuracy: 0.8106
Epoch 15/25
320/320 - 76s - loss: 0.3517 - accuracy: 0.8416 - val_loss: 0.3837 - val_accuracy: 0.8197
Epoch 16/25
320/320 - 77s - loss: 0.3424 - accuracy: 0.8458 - val_loss: 0.3905 - val_accuracy: 0.8153
Epoch 17/25
320/320 - 77s - loss: 0.3344 - accuracy: 0.8499 - val_loss: 0.3875 - val_accuracy: 0.8167
Epoch 18/25
320/320 - 77s - loss: 0.3272 - accuracy: 0.8535 - val_loss: 0.3957 - val_accuracy: 0.8102
Epoch 19/25
320/320 - 77s - loss: 0.3189 - accuracy: 0.8583 - val_loss: 0.3894 - val_accuracy: 0.8131
Epoch 20/25
320/320 - 77s - loss: 0.3115 - accuracy: 0.8620 - val_loss: 0.3847 - val_accuracy: 0.8224
Epoch 21/25
320/320 - 77s - loss: 0.3032 - accuracy: 0.8672 - val_loss: 0.3847 - val_accuracy: 0.8172
Epoch 22/25
320/320 - 76s - loss: 0.2962 - accuracy: 0.8698 - val_loss: 0.3866 - val_accuracy: 0.8199
Epoch 23/25
320/320 - 77s - loss: 0.2883 - accuracy: 0.8739 - val_loss: 0.3845 - val_accuracy: 0.8217
Epoch 24/25
320/320 - 76s - loss: 0.2808 - accuracy: 0.8768 - val_loss: 0.3939 - val_accuracy: 0.8205
Epoch 25/25
320/320 - 76s - loss: 0.2736 - accuracy: 0.8817 - val_loss: 0.3983 - val_accuracy: 0.8179
Training ended at 2021-05-16 10:54:24.665313
Minutes elapsed: 32.719384


#### history
    epoch  training  validation
0       1  0.691017    0.719982
1       2  0.743088    0.760244
2       3  0.760186    0.761563
3       4  0.770678    0.781296
4       5  0.780908    0.773765
5       6  0.788740    0.784374
6       7  0.796326    0.792261
7       8  0.803429    0.795202
8       9  0.810941    0.800890
9      10  0.816932    0.805700
10     11  0.821793    0.807761
11     12  0.827476    0.810702
12     13  0.832316    0.815648
13     14  0.837306    0.810619
14     15  0.841566    0.819661
15     16  0.845844    0.815346
16     17  0.849900    0.816665
17     18  0.853488    0.810179
18     19  0.858273    0.813148
19     20  0.861977    0.822437
20     21  0.867202    0.817187
21     22  0.869761    0.819881
22     23  0.873911    0.821750
23     24  0.876821    0.820485
24     25  0.881661    0.817902


#### max acc
Maximum accuracy at epoch 20 = 0.8224

#### test performance
loss = 0.3794, accuracy = 0.8254

