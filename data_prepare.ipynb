{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3613jvsc74a57bd0c74f9c493e099d7c35d745791a13e35fe9e1e7bfcd9d70da72fbd6c2b1c73851",
      "display_name": "Python 3.6.13 64-bit ('tfenv': conda)"
    },
    "colab": {
      "name": "data_prepare.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QVcwQ2B9KDbw",
        "uRLf3jbUKDb3",
        "PWo85vToK1TK"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_vd28PDKDbW"
      },
      "source": [
        "# Quora Question Pair - Process Raw Data\n",
        "\n",
        " - created in 2021/5/9, Zhu Zhongbo, first trial with kaggle solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDbgcU6cKLE7",
        "outputId": "92764bd1-e43d-4198-9f85-3b7296aad341"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRFGd1dSKaJH",
        "outputId": "92b952cf-e007-48c5-f8cb-523484278089"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fCS4b8uKrI6",
        "outputId": "89c8053e-1e1a-478e-95ea-bcec223a6cfa"
      },
      "source": [
        "% cd /content/drive/MyDrive/QuoraQuestionPair/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/QuoraQuestionPair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4uCcj_fKDbc"
      },
      "source": [
        "## Modules and global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN85aR_hKDbe"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import csv,json\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from string import punctuation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from os.path import expanduser, exists\n",
        "from keras.utils.data_utils import get_file"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM2yNgy9KDbh"
      },
      "source": [
        " - codecs â€“ String encoding and decoding\n",
        "Purpose:\tEncoders and decoders for converting text between different representations.\n",
        "Available In:\t2.1 and later\n",
        "The codecs module provides stream and file interfaces for transcoding data in your program. It is most commonly used to work with Unicode text, but other encodings are also available for other purposes.\n",
        "\n",
        "- keras - api based on tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDzWkhxLKDbi"
      },
      "source": [
        "BASE_DIR = './data/'\n",
        "KERAS_DATASETS_DIR = expanduser('~/.keras/datasets/')\n",
        "GLOVE_ZIP_FILE_URL = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
        "GLOVE_ZIP_FILE = 'glove.840B.300d.zip'\n",
        "GLOVE_FILE = 'glove.840B.300d.txt'\n",
        "TRAIN_DATA_FILE = BASE_DIR + 'train.csv'\n",
        "TEST_DATA_FILE = BASE_DIR + 'test.csv'\n",
        "TRAIN_FEAT_FILE = BASE_DIR + 'X_train.csv'\n",
        "TEST_FEAT_FILE = BASE_DIR + 'X_test.csv'\n",
        "COMPLETE_TRAIN_FEAT_FILE = BASE_DIR + 'X_train_full.csv'\n",
        "COMPLETE_TEST_FEAT_FILE = BASE_DIR + 'X_test_full.csv'\n",
        "# params\n",
        "MAX_SEQUENCE_LENGTH = 30\n",
        "MAX_NB_WORDS = 200000\n",
        "EMBEDDING_DIM = 300\n",
        "VALIDATION_SPLIT = 0.1\n",
        "# output files\n",
        "Q1_TRAINING_DATA_FILE = 'q1_train.npy'\n",
        "Q2_TRAINING_DATA_FILE = 'q2_train.npy'\n",
        "Q1_TEST_DATA_FILE = 'q1_test.npy'\n",
        "Q2_TEST_DATA_FILE = 'q2_test.npy'\n",
        "TEST_ID_FILE = 'test_ids.npy'\n",
        "LABEL_TRAINING_DATA_FILE = 'label_train.npy'\n",
        "WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix.npy'\n",
        "NB_WORDS_DATA_FILE = 'nb_words.json'\n",
        "TRAIN_FEAT_NPY_FILE = 'train_feat_array.npy'\n",
        "TEST_FEAT_NPY_FILE = 'test_feat_array.npy'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODhkD7UJKDbk"
      },
      "source": [
        "## Data Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXTKTWCbKDbl",
        "outputId": "63f1d1c1-8f09-4943-c3d4-c5a6a9313276"
      },
      "source": [
        "# The function \"text_to_wordlist\" is from\n",
        "# https://www.kaggle.com/currie32/quora-question-pairs/the-importance-of-cleaning-text\n",
        "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
        "    # Clean the text, with the option to remove stopwords and to stem words.\n",
        "    \n",
        "    # Convert words to lower case and split them\n",
        "    text = text.lower().split()\n",
        "\n",
        "    # Optionally, remove stop words\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "    \n",
        "    text = \" \".join(text)\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    \n",
        "    # Optionally, shorten words to their stems\n",
        "    if stem_words:\n",
        "        text = text.split()\n",
        "        stemmer = SnowballStemmer('english')\n",
        "        stemmed_words = [stemmer.stem(word) for word in text]\n",
        "        text = \" \".join(stemmed_words)\n",
        "    \n",
        "    # Return a list of words\n",
        "    return(text)\n",
        "\n",
        "texts_1 = [] \n",
        "texts_2 = []\n",
        "labels = []\n",
        "with codecs.open(TRAIN_DATA_FILE, encoding='utf-8') as f:\n",
        "    reader = csv.reader(f, delimiter=',')\n",
        "    header = next(reader)\n",
        "    for values in reader:\n",
        "        texts_1.append(text_to_wordlist(values[3]))\n",
        "        texts_2.append(text_to_wordlist(values[4]))\n",
        "        labels.append(int(values[5]))\n",
        "print('Found %s texts in train.csv' % len(texts_1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 404290 texts in train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tEtS6FsKDbo",
        "outputId": "09cc3776-f969-495b-805e-83cd812073a1"
      },
      "source": [
        "print(texts_1[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what is the step by step guide to invest in share market in india ', 'what is the story of kohinoor koh - i - noor diamond ', 'how can i increase the speed of my internet connection while using a vpn ', 'why am i mentally very lonely how can i solve it ', 'which one dissolve in water quikly sugar salt methane and carbon di oxide ', 'astrology : i am a capricorn sun cap moon and cap rising what does that say about me ', 'should i buy tiago ', 'how can i be a good geologist ', 'when do you use instead of ', 'motorola company : can i hack my charter motorolla dcx3400 ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muXzeOxfKDbq",
        "outputId": "fab2f028-8b6f-473a-8a2d-bfd7fd7fabb4"
      },
      "source": [
        "print(texts_2[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what is the step by step guide to invest in share market ', 'what would happen if the indian government stole the kohinoor koh - i - noor diamond back ', 'how can internet speed be increased by hacking through dns ', 'find the remainder when math 23 ^ 24 math is divided by 24 23 ', 'which fish would survive in salt water ', 'i am a triple capricorn sun moon and ascendant in capricorn what does this say about me ', 'what keeps childern active and far from phone and video games ', 'what should i do to be a great geologist ', 'when do you use instead of and ', 'how do i hack motorola dcx3400 for free internet ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK_Som0QKDbs",
        "outputId": "1225c8f6-505d-48ad-8bee-425c6ccc8589"
      },
      "source": [
        "print(labels[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvRGYxdLKDbt",
        "outputId": "1b119ffd-ded8-43f2-8b91-27ed823ff322"
      },
      "source": [
        "test_texts_1 = []\n",
        "test_texts_2 = []\n",
        "test_ids = []\n",
        "with codecs.open(TEST_DATA_FILE, encoding='utf-8') as f:\n",
        "    reader = csv.reader(f, delimiter=',')\n",
        "    header = next(reader)\n",
        "    for values in reader:\n",
        "        test_texts_1.append(text_to_wordlist(values[1]))\n",
        "        test_texts_2.append(text_to_wordlist(values[2]))\n",
        "        test_ids.append(values[0])\n",
        "print('Found %s texts in test.csv' % len(test_texts_1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2345796 texts in test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcbj20OgKDbu",
        "outputId": "461de02a-b60d-420c-f9ad-a590f39b48bd"
      },
      "source": [
        "print(test_texts_1[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['how does the surface pro himself 4 compare with ipad pro ', 'should i have a hair transplant at age 24 how much would it cost ', 'what but is the best way to send money from china to the us ', 'which food not emulsifiers ', 'how aberystwyth start reading ', 'how are the two wheeler insurance from bharti axa insurance ', 'how can i reduce my belly fat through a diet ', 'by scrapping the 500 and 1000 rupee notes how is rbi planning to fight against issue black money ', 'what are the how best books of all time ', 'after 12th years old boy and i had sex with a 12 years old girl with her consent is there anything wrong ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyr09_0_KDbv",
        "outputId": "d93417fe-5912-454a-999c-ef2d61c8ce6b"
      },
      "source": [
        "print(test_ids[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVcwQ2B9KDbw"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEITlkOmKDbx"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts_1 + texts_2 + test_texts_1 + test_texts_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agv0TG0aKDby"
      },
      "source": [
        "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
        "sequences_2 = tokenizer.texts_to_sequences(texts_2)\n",
        "test_sequences_1 = tokenizer.texts_to_sequences(test_texts_1)\n",
        "test_sequences_2 = tokenizer.texts_to_sequences(test_texts_2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqdjH-tKKDby"
      },
      "source": [
        "print(sequences_1[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9WU4iGbKDbz"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04NFNDbZKDb0"
      },
      "source": [
        "print(list(word_index.items())[0:30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1jBUK6SKDb1"
      },
      "source": [
        "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = np.array(labels)\n",
        "print('Shape of data tensor:', data_1.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xADsKfZ9KDb1"
      },
      "source": [
        "print(type(data_1))\n",
        "print(data_1[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSs5js6hKDb2"
      },
      "source": [
        "test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_ids = np.array(test_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liC-eTpyKDb3"
      },
      "source": [
        "print(type(test_data_1[0:10]))\n",
        "print(test_data_1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRLf3jbUKDb3"
      },
      "source": [
        "## GLOVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYaQq756KDb4",
        "outputId": "3e2bc583-5a13-45fc-c422-5799c509d440"
      },
      "source": [
        "if not exists(KERAS_DATASETS_DIR + GLOVE_ZIP_FILE):\n",
        "    print(\"no such zip file, download it\")\n",
        "    zipfile = ZipFile(get_file(GLOVE_ZIP_FILE, GLOVE_ZIP_FILE_URL))\n",
        "    zipfile.extract(GLOVE_FILE, path=KERAS_DATASETS_DIR)\n",
        "elif exists(KERAS_DATASETS_DIR + GLOVE_ZIP_FILE) and (not exists(KERAS_DATASETS_DIR + GLOVE_FILE)):\n",
        "    print(\"had the zip file, extract it\")\n",
        "    zipfile = ZipFile(KERAS_DATASETS_DIR+GLOVE_ZIP_FILE)\n",
        "    zipfile.extract(GLOVE_FILE, path=KERAS_DATASETS_DIR)\n",
        "\n",
        "print(\"Processing\", GLOVE_FILE)\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(KERAS_DATASETS_DIR + GLOVE_FILE, encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split(' ')\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = embedding\n",
        "\n",
        "print('Word embeddings: %d' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "had the zip file, extract it\n",
            "Processing glove.840B.300d.txt\n",
            "Word embeddings: 2196016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIWKr6n7KDb5",
        "outputId": "71a01a93-fc06-46d4-e806-3820982dc0c7"
      },
      "source": [
        "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
        "word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NB_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        word_embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null word embeddings: 33233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M19dYt4gKDb6",
        "outputId": "6d90b1e3-1571-4acc-bc01-96bb534642ad"
      },
      "source": [
        "print('Shape of question1 data tensor:', data_1.shape)\n",
        "print('Shape of question2 data tensor:', data_2.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "print('Shape of question1 test data tensor:', test_data_1.shape)\n",
        "print('Shape of question2 test data tensor:', test_data_2.shape)\n",
        "print('Shape of label tensor:', test_ids.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of question1 data tensor: (404290, 30)\n",
            "Shape of question2 data tensor: (404290, 30)\n",
            "Shape of label tensor: (404290,)\n",
            "Shape of question1 test data tensor: (2345796, 30)\n",
            "Shape of question2 test data tensor: (2345796, 30)\n",
            "Shape of label tensor: (2345796,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7chXFfm4KDb7"
      },
      "source": [
        "np.save(open(Q1_TRAINING_DATA_FILE, 'wb'), data_1)\n",
        "np.save(open(Q2_TRAINING_DATA_FILE, 'wb'), data_2)\n",
        "np.save(open(Q1_TEST_DATA_FILE, 'wb'), test_data_1)\n",
        "np.save(open(Q2_TEST_DATA_FILE, 'wb'), test_data_2)\n",
        "np.save(open(TEST_ID_FILE, 'wb'), test_ids)\n",
        "np.save(open(LABEL_TRAINING_DATA_FILE, 'wb'), labels)\n",
        "np.save(open(WORD_EMBEDDING_MATRIX_FILE, 'wb'), word_embedding_matrix)\n",
        "with open(NB_WORDS_DATA_FILE, 'w') as f:\n",
        "    json.dump({'nb_words': nb_words}, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3fLNNg_KDb7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coyQoQS2XY3h"
      },
      "source": [
        "## Merge More Features Into One File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLCFP-ojYuuX"
      },
      "source": [
        "def extend_file(input_fname, data_frame_orig):\n",
        "  fpath = BASE_DIR + input_fname\n",
        "  pf = pd.read_csv(fpath)\n",
        "  pf.fillna(value=0)\n",
        "  print(pf.shape)\n",
        "  new_data_frame = pd.concat([data_frame_orig, pf], axis=1)\n",
        "  return new_data_frame"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404290, 17), (2345796, 17))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "x_train_orig = pd.read_csv(TRAIN_FEAT_FILE)\n",
        "x_test_orig = pd.read_csv(TEST_FEAT_FILE)\n",
        "x_train_orig.shape, x_test_orig.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404290, 73)\n",
            "(2345796, 73)\n"
          ]
        }
      ],
      "source": [
        "# merge things here\n",
        "X_train = extend_file('extra_train_feat.csv', x_train_orig)\n",
        "X_test = extend_file('extra_test_feat.csv', x_test_orig)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox88vM5nUCHk"
      },
      "source": [
        "# save to csv files\n",
        "X_train.to_csv(COMPLETE_TRAIN_FEAT_FILE, index=False)\n",
        "X_test.to_csv(COMPLETE_TEST_FEAT_FILE, index=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX3JDIForNSd",
        "outputId": "3a30ea32-0d3e-4e05-bbe0-3921b8bdd595"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404290, 90), (2345796, 90))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "del X_train\n",
        "del X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWo85vToK1TK"
      },
      "source": [
        "## Feature Extraction + Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntOWgJ2bQLnI"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy5iE96JK6m_",
        "outputId": "d1be21f6-bc11-4548-9c32-50e753dc57f6"
      },
      "source": [
        "# new feaatures\n",
        "train_feat = pd.read_csv(COMPLETE_TRAIN_FEAT_FILE)\n",
        "test_feat = pd.read_csv(COMPLETE_TEST_FEAT_FILE)\n",
        "train_feat = train_feat.fillna(value=0)\n",
        "test_feat = test_feat.fillna(value=0)\n",
        "train_feat.shape, test_feat.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404290, 90), (2345796, 90))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "GqzrlxtAPtWt",
        "outputId": "c17df17a-3f7a-4aad-fb50-6afdc49b7ae6"
      },
      "source": [
        "train_feat"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        word_match  tfidf_wm  tfidf_wm_stops   jaccard  wc_diff  wc_ratio  \\\n",
              "0         0.727273  0.796024        0.772164  0.769231        2  0.857143   \n",
              "1         0.307692  0.359200        0.361758  0.250000        5  1.625000   \n",
              "2         0.363636  0.304783        0.355191  0.200000        4  0.714286   \n",
              "3         0.000000  0.000000        0.000000  0.000000        2  0.818182   \n",
              "4         0.000000  0.034253        0.000000  0.111111        6  0.538462   \n",
              "...            ...       ...             ...       ...      ...       ...   \n",
              "404285    0.857143  0.837624        0.828152  0.785714        1  0.928571   \n",
              "404286    0.666667  0.683850        0.657463  0.454545        1  1.125000   \n",
              "404287    0.500000  0.602845        0.712011  0.166667        1  0.750000   \n",
              "404288    0.000000  0.005178        0.000000  0.025641        8  1.470588   \n",
              "404289    1.000000  0.932658        1.000000  0.800000        2  1.250000   \n",
              "\n",
              "        wc_diff_unique  wc_ratio_unique  wc_diff_unq_stop  \\\n",
              "0                    1         0.916667                 1   \n",
              "1                    4         1.500000                 5   \n",
              "2                    4         0.714286                 1   \n",
              "3                    1         0.900000                 1   \n",
              "4                    6         0.538462                 5   \n",
              "...                ...              ...               ...   \n",
              "404285               1         0.923077                 0   \n",
              "404286               0         1.000000                 0   \n",
              "404287               1         0.750000                 0   \n",
              "404288               6         1.352941                 4   \n",
              "404289               2         1.250000                 0   \n",
              "\n",
              "        wc_ratio_unique_stop  ...  tfidf_mean2  tfidf_len1  tfidf_len2  \\\n",
              "0                   0.833333  ...     0.417370           6           5   \n",
              "1                   2.250000  ...     0.340163           5           8   \n",
              "2                   0.833333  ...     0.440659           6           5   \n",
              "3                   1.250000  ...     0.433367           3           5   \n",
              "4                   0.500000  ...     0.496439           9           4   \n",
              "...                      ...  ...          ...         ...         ...   \n",
              "404285              1.000000  ...     0.398473           6           6   \n",
              "404286              1.000000  ...     0.571469           3           3   \n",
              "404287              1.000000  ...     1.000000           1           1   \n",
              "404288              1.444444  ...     0.268516           9          13   \n",
              "404289              1.000000  ...     0.549040           3           3   \n",
              "\n",
              "        graph_clique_feat         q1_pr         q2_pr  q1_freq  q2_freq  \\\n",
              "0                     2.0  1.608405e-07  3.047505e-07        1        2   \n",
              "1                     8.0  8.189555e-07  3.094298e-07        8        3   \n",
              "2                     2.0  3.047507e-07  1.608406e-07        2        1   \n",
              "3                     0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "4                     3.0  3.404968e-07  1.277957e-07        3        1   \n",
              "...                   ...           ...           ...      ...      ...   \n",
              "404285                3.0  1.933878e-07  1.952633e-07        3        3   \n",
              "404286               15.0  4.349779e-07  4.397159e-07       15       15   \n",
              "404287                0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "404288                0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "404289                0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "\n",
              "        q1_q2_intersect  q1_q2_wm_ratio  \n",
              "0                     0        0.000000  \n",
              "1                     0        0.000000  \n",
              "2                     0        0.000000  \n",
              "3                     0        0.000000  \n",
              "4                     0        0.000000  \n",
              "...                 ...             ...  \n",
              "404285                0        0.000000  \n",
              "404286               13        0.863133  \n",
              "404287                0        0.000000  \n",
              "404288                0        0.000000  \n",
              "404289                0        0.000000  \n",
              "\n",
              "[404290 rows x 90 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_match</th>\n      <th>tfidf_wm</th>\n      <th>tfidf_wm_stops</th>\n      <th>jaccard</th>\n      <th>wc_diff</th>\n      <th>wc_ratio</th>\n      <th>wc_diff_unique</th>\n      <th>wc_ratio_unique</th>\n      <th>wc_diff_unq_stop</th>\n      <th>wc_ratio_unique_stop</th>\n      <th>...</th>\n      <th>tfidf_mean2</th>\n      <th>tfidf_len1</th>\n      <th>tfidf_len2</th>\n      <th>graph_clique_feat</th>\n      <th>q1_pr</th>\n      <th>q2_pr</th>\n      <th>q1_freq</th>\n      <th>q2_freq</th>\n      <th>q1_q2_intersect</th>\n      <th>q1_q2_wm_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.727273</td>\n      <td>0.796024</td>\n      <td>0.772164</td>\n      <td>0.769231</td>\n      <td>2</td>\n      <td>0.857143</td>\n      <td>1</td>\n      <td>0.916667</td>\n      <td>1</td>\n      <td>0.833333</td>\n      <td>...</td>\n      <td>0.417370</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2.0</td>\n      <td>1.608405e-07</td>\n      <td>3.047505e-07</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.307692</td>\n      <td>0.359200</td>\n      <td>0.361758</td>\n      <td>0.250000</td>\n      <td>5</td>\n      <td>1.625000</td>\n      <td>4</td>\n      <td>1.500000</td>\n      <td>5</td>\n      <td>2.250000</td>\n      <td>...</td>\n      <td>0.340163</td>\n      <td>5</td>\n      <td>8</td>\n      <td>8.0</td>\n      <td>8.189555e-07</td>\n      <td>3.094298e-07</td>\n      <td>8</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.363636</td>\n      <td>0.304783</td>\n      <td>0.355191</td>\n      <td>0.200000</td>\n      <td>4</td>\n      <td>0.714286</td>\n      <td>4</td>\n      <td>0.714286</td>\n      <td>1</td>\n      <td>0.833333</td>\n      <td>...</td>\n      <td>0.440659</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2.0</td>\n      <td>3.047507e-07</td>\n      <td>1.608406e-07</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>0.818182</td>\n      <td>1</td>\n      <td>0.900000</td>\n      <td>1</td>\n      <td>1.250000</td>\n      <td>...</td>\n      <td>0.433367</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.034253</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>6</td>\n      <td>0.538462</td>\n      <td>6</td>\n      <td>0.538462</td>\n      <td>5</td>\n      <td>0.500000</td>\n      <td>...</td>\n      <td>0.496439</td>\n      <td>9</td>\n      <td>4</td>\n      <td>3.0</td>\n      <td>3.404968e-07</td>\n      <td>1.277957e-07</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>404285</th>\n      <td>0.857143</td>\n      <td>0.837624</td>\n      <td>0.828152</td>\n      <td>0.785714</td>\n      <td>1</td>\n      <td>0.928571</td>\n      <td>1</td>\n      <td>0.923077</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.398473</td>\n      <td>6</td>\n      <td>6</td>\n      <td>3.0</td>\n      <td>1.933878e-07</td>\n      <td>1.952633e-07</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>404286</th>\n      <td>0.666667</td>\n      <td>0.683850</td>\n      <td>0.657463</td>\n      <td>0.454545</td>\n      <td>1</td>\n      <td>1.125000</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.571469</td>\n      <td>3</td>\n      <td>3</td>\n      <td>15.0</td>\n      <td>4.349779e-07</td>\n      <td>4.397159e-07</td>\n      <td>15</td>\n      <td>15</td>\n      <td>13</td>\n      <td>0.863133</td>\n    </tr>\n    <tr>\n      <th>404287</th>\n      <td>0.500000</td>\n      <td>0.602845</td>\n      <td>0.712011</td>\n      <td>0.166667</td>\n      <td>1</td>\n      <td>0.750000</td>\n      <td>1</td>\n      <td>0.750000</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>404288</th>\n      <td>0.000000</td>\n      <td>0.005178</td>\n      <td>0.000000</td>\n      <td>0.025641</td>\n      <td>8</td>\n      <td>1.470588</td>\n      <td>6</td>\n      <td>1.352941</td>\n      <td>4</td>\n      <td>1.444444</td>\n      <td>...</td>\n      <td>0.268516</td>\n      <td>9</td>\n      <td>13</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>404289</th>\n      <td>1.000000</td>\n      <td>0.932658</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>2</td>\n      <td>1.250000</td>\n      <td>2</td>\n      <td>1.250000</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.549040</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>404290 rows Ã— 90 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "jVz3okn-t8Me",
        "outputId": "79ccae4d-5ad8-4a04-adfd-fbdc06d055b3"
      },
      "source": [
        "test_feat"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word_match  tfidf_wm  tfidf_wm_stops   jaccard  wc_diff  wc_ratio  \\\n",
              "0          0.266667  0.245900        0.290094  0.090909        3  1.272727   \n",
              "1          0.500000  0.439759        0.480962  0.235294        7  0.500000   \n",
              "2          0.444444  0.418727        0.468893  0.285714        8  0.428571   \n",
              "3          0.000000  0.000000        0.000000  0.000000        1  0.750000   \n",
              "4          0.800000  0.851476        1.000000  0.428571        2  1.500000   \n",
              "...             ...       ...             ...       ...      ...       ...   \n",
              "2345791    0.000000  0.000000        0.000000  0.000000        2  0.818182   \n",
              "2345792    0.222222  0.223549        0.238630  0.076923        4  0.555556   \n",
              "2345793    0.000000  0.000000        0.000000  0.000000        1  0.888889   \n",
              "2345794    0.869565  0.887973        0.936711  0.739130        0  1.000000   \n",
              "2345795    0.444444  0.506593        0.565062  0.133333        1  1.125000   \n",
              "\n",
              "         wc_diff_unique  wc_ratio_unique  wc_diff_unq_stop  \\\n",
              "0                     2         1.181818                 3   \n",
              "1                     7         0.500000                 2   \n",
              "2                     6         0.500000                 3   \n",
              "3                     1         0.750000                 0   \n",
              "4                     2         1.500000                 1   \n",
              "...                 ...              ...               ...   \n",
              "2345791               2         0.818182                 3   \n",
              "2345792               4         0.555556                 1   \n",
              "2345793               2         0.777778                 2   \n",
              "2345794               0         1.000000                 1   \n",
              "2345795               1         1.125000                 1   \n",
              "\n",
              "         wc_ratio_unique_stop  ...  tfidf_mean2  tfidf_len1  tfidf_len2  \\\n",
              "0                    1.500000  ...     0.314640           5           9   \n",
              "1                    0.714286  ...     0.430365           5           5   \n",
              "2                    0.500000  ...     0.571907           5           3   \n",
              "3                    1.000000  ...     0.699928           2           2   \n",
              "4                    0.666667  ...     0.699651           3           2   \n",
              "...                       ...  ...          ...         ...         ...   \n",
              "2345791              0.571429  ...     0.488174           8           4   \n",
              "2345792              0.800000  ...     0.492754           5           4   \n",
              "2345793              0.666667  ...     0.443660           5           5   \n",
              "2345794              1.090909  ...     0.288907          10          11   \n",
              "2345795              0.800000  ...     0.568653           5           3   \n",
              "\n",
              "         graph_clique_feat         q1_pr         q2_pr  q1_freq  q2_freq  \\\n",
              "0                      0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "1                      2.0  2.366496e-07  2.193292e-07        2        2   \n",
              "2                      0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "3                      0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "4                      0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "...                    ...           ...           ...      ...      ...   \n",
              "2345791                0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "2345792                0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "2345793                0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "2345794                0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "2345795                0.0  2.088105e-07  2.088105e-07        1        1   \n",
              "\n",
              "         q1_q2_intersect  q1_q2_wm_ratio  \n",
              "0                      0             0.0  \n",
              "1                      0             0.0  \n",
              "2                      0             0.0  \n",
              "3                      0             0.0  \n",
              "4                      0             0.0  \n",
              "...                  ...             ...  \n",
              "2345791                0             0.0  \n",
              "2345792                0             0.0  \n",
              "2345793                0             0.0  \n",
              "2345794                0             0.0  \n",
              "2345795                0             0.0  \n",
              "\n",
              "[2345796 rows x 90 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_match</th>\n      <th>tfidf_wm</th>\n      <th>tfidf_wm_stops</th>\n      <th>jaccard</th>\n      <th>wc_diff</th>\n      <th>wc_ratio</th>\n      <th>wc_diff_unique</th>\n      <th>wc_ratio_unique</th>\n      <th>wc_diff_unq_stop</th>\n      <th>wc_ratio_unique_stop</th>\n      <th>...</th>\n      <th>tfidf_mean2</th>\n      <th>tfidf_len1</th>\n      <th>tfidf_len2</th>\n      <th>graph_clique_feat</th>\n      <th>q1_pr</th>\n      <th>q2_pr</th>\n      <th>q1_freq</th>\n      <th>q2_freq</th>\n      <th>q1_q2_intersect</th>\n      <th>q1_q2_wm_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.266667</td>\n      <td>0.245900</td>\n      <td>0.290094</td>\n      <td>0.090909</td>\n      <td>3</td>\n      <td>1.272727</td>\n      <td>2</td>\n      <td>1.181818</td>\n      <td>3</td>\n      <td>1.500000</td>\n      <td>...</td>\n      <td>0.314640</td>\n      <td>5</td>\n      <td>9</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.500000</td>\n      <td>0.439759</td>\n      <td>0.480962</td>\n      <td>0.235294</td>\n      <td>7</td>\n      <td>0.500000</td>\n      <td>7</td>\n      <td>0.500000</td>\n      <td>2</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>0.430365</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2.0</td>\n      <td>2.366496e-07</td>\n      <td>2.193292e-07</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.444444</td>\n      <td>0.418727</td>\n      <td>0.468893</td>\n      <td>0.285714</td>\n      <td>8</td>\n      <td>0.428571</td>\n      <td>6</td>\n      <td>0.500000</td>\n      <td>3</td>\n      <td>0.500000</td>\n      <td>...</td>\n      <td>0.571907</td>\n      <td>5</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.750000</td>\n      <td>1</td>\n      <td>0.750000</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.699928</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.800000</td>\n      <td>0.851476</td>\n      <td>1.000000</td>\n      <td>0.428571</td>\n      <td>2</td>\n      <td>1.500000</td>\n      <td>2</td>\n      <td>1.500000</td>\n      <td>1</td>\n      <td>0.666667</td>\n      <td>...</td>\n      <td>0.699651</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2345791</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>0.818182</td>\n      <td>2</td>\n      <td>0.818182</td>\n      <td>3</td>\n      <td>0.571429</td>\n      <td>...</td>\n      <td>0.488174</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2345792</th>\n      <td>0.222222</td>\n      <td>0.223549</td>\n      <td>0.238630</td>\n      <td>0.076923</td>\n      <td>4</td>\n      <td>0.555556</td>\n      <td>4</td>\n      <td>0.555556</td>\n      <td>1</td>\n      <td>0.800000</td>\n      <td>...</td>\n      <td>0.492754</td>\n      <td>5</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2345793</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.888889</td>\n      <td>2</td>\n      <td>0.777778</td>\n      <td>2</td>\n      <td>0.666667</td>\n      <td>...</td>\n      <td>0.443660</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2345794</th>\n      <td>0.869565</td>\n      <td>0.887973</td>\n      <td>0.936711</td>\n      <td>0.739130</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>1.090909</td>\n      <td>...</td>\n      <td>0.288907</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2345795</th>\n      <td>0.444444</td>\n      <td>0.506593</td>\n      <td>0.565062</td>\n      <td>0.133333</td>\n      <td>1</td>\n      <td>1.125000</td>\n      <td>1</td>\n      <td>1.125000</td>\n      <td>1</td>\n      <td>0.800000</td>\n      <td>...</td>\n      <td>0.568653</td>\n      <td>5</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>2.088105e-07</td>\n      <td>2.088105e-07</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2345796 rows Ã— 90 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgD7Dxr-QH8u",
        "outputId": "7355863e-f447-4f8d-d10a-7108f394d67b"
      },
      "source": [
        "train_feat = train_feat.replace([np.inf, -np.inf], 0)\n",
        "test_feat = test_feat.replace([np.inf, -np.inf], 0)\n",
        "train_feat.shape, test_feat.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404290, 90), (2345796, 90))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38i47ZKBQJcp",
        "outputId": "9a6b0e53-d8c5-4f52-c8a5-f2a48bd121fd"
      },
      "source": [
        "ss = StandardScaler()\n",
        "\n",
        "train_feat_ss = train_feat[train_feat.columns.values]\n",
        "test_feat_ss = test_feat[test_feat.columns.values]\n",
        "\n",
        "np.vstack((train_feat_ss, test_feat_ss)).shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2750086, 90)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M17yUMmoRlta"
      },
      "source": [
        "ss.fit(np.vstack((train_feat_ss, test_feat_ss)))\n",
        "train_feat_ss = ss.transform(train_feat_ss)\n",
        "test_feat_ss = ss.transform(test_feat_ss)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iERso6lkT5zG",
        "outputId": "6efe0896-d284-4cdb-9450-16798006dc0c"
      },
      "source": [
        "print(type(train_feat_ss))\n",
        "print(type(test_feat_ss))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcqyvhkZYkG0",
        "outputId": "31c4b18b-5e9c-4027-bb67-161f6266a0a0"
      },
      "source": [
        "train_feat_ss"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.73268924,  2.06181366,  1.85449699, ..., -0.04504227,\n",
              "        -0.11478188, -0.24204707],\n",
              "       [ 0.05078041,  0.26531904,  0.25809247, ..., -0.03159392,\n",
              "        -0.11478188, -0.24204707],\n",
              "       [ 0.27503492,  0.04151896,  0.23255036, ..., -0.05849061,\n",
              "        -0.11478188, -0.24204707],\n",
              "       ...,\n",
              "       [ 0.82165529,  1.26733775,  1.62051008, ..., -0.05849061,\n",
              "        -0.11478188, -0.24204707],\n",
              "       [-1.1826194 , -1.19064572, -1.14907551, ..., -0.05849061,\n",
              "        -0.11478188, -0.24204707],\n",
              "       [ 2.82592999,  2.62373743,  2.74073429, ..., -0.05849061,\n",
              "        -0.11478188, -0.24204707]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_xjYQwLYmDw",
        "outputId": "006451c8-52fb-4060-ccb4-105494eba6ff"
      },
      "source": [
        "test_feat_ss"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1136729 , -0.20064503, -0.02066457, ..., -0.05849061,\n",
              "        -0.11478188, -0.24204707],\n",
              "       [ 0.82165529,  0.5966286 ,  0.72177347, ..., -0.04504227,\n",
              "        -0.11478188, -0.24204707],\n",
              "       [ 0.59895811,  0.51012821,  0.67483084, ..., -0.05849061,\n",
              "        -0.11478188, -0.24204707],\n",
              "       ...,\n",
              "       [-1.1826194 , -1.21194048, -1.14907551, ..., -0.05849061,\n",
              "        -0.11478188, -0.24204707],\n",
              "       [ 2.30307572,  2.43996797,  2.49455362, ..., -0.05849061,\n",
              "        -0.11478188, -0.24204707],\n",
              "       [ 0.59895811,  0.87149159,  1.048907  , ..., -0.05849061,\n",
              "        -0.11478188, -0.24204707]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tQzCfQ1T6mY"
      },
      "source": [
        "np.save(open(TRAIN_FEAT_NPY_FILE, 'wb'), train_feat_ss)\n",
        "np.save(open(TEST_FEAT_NPY_FILE, 'wb'), test_feat_ss)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgICWs5FXhUp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}