{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Models\n",
    "Initially single xgb model was created, finally 7 LSTM models were created with random dense layers and dropouts and averaged with 6 xgb models with random hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Features\n",
    "Features were created using feature_engineering.ipynb and page_rank.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_difflib = pd.read_csv('data/train_feature_difflib.csv')\n",
    "train_embedding = pd.read_csv('data/train_feature_embedding.csv')\n",
    "train_embedding2 = pd.read_csv('data/train_feature_embedding_2.csv')\n",
    "train_fuzz = pd.read_csv('data/train_feature_fuzz.csv')\n",
    "train_len = pd.read_csv('data/train_feature_len.csv')\n",
    "#train_match = pd.read_csv('train_feature_match.csv')\n",
    "train_match_2 = pd.read_csv('data/train_feature_match_2.csv')\n",
    "#train_oof = pd.read_csv('train_feature_oof.csv')\n",
    "#train_simhash = pd.read_csv('train_feature_simhash.csv')\n",
    "train_tfidf = pd.read_csv('data/train_feature_tfidf.csv')\n",
    "\n",
    "train_graph_clique = pd.read_csv('data/train_feature_graph_clique.csv')\n",
    "train_graph_pagerank = pd.read_csv('data/train_feature_graph_pagerank.csv')\n",
    "train_graph_freq = pd.read_csv('data/train_feature_graph_question_freq.csv')\n",
    "train_graph_intersect = pd.read_csv('data/train_feature_graph_intersect.csv')\n",
    "X_train = pd.concat([\n",
    "        train_difflib,\n",
    "        train_embedding,\n",
    "        train_embedding2,\n",
    "        train_fuzz,\n",
    "        train_len,\n",
    "        #train_match,\n",
    "        train_match_2,\n",
    "        #train_oof,\n",
    "        #train_simhash,\n",
    "        train_tfidf,\n",
    "        train_graph_clique,\n",
    "        train_graph_pagerank,\n",
    "        train_graph_freq,\n",
    "        train_graph_intersect,\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_difflib = pd.read_csv('data/test_feature_difflib.csv')\n",
    "test_embedding = pd.read_csv('data/test_feature_embedding.csv')\n",
    "test_embedding2 = pd.read_csv('data/test_feature_embedding_2.csv')\n",
    "test_fuzz = pd.read_csv('data/test_feature_fuzz.csv')\n",
    "test_len = pd.read_csv('data/test_feature_len.csv')\n",
    "#test_match = pd.read_csv('test_feature_match.csv')\n",
    "test_match_2 = pd.read_csv('data/test_feature_match_2.csv')\n",
    "#test_oof = pd.read_csv('test_feature_oof.csv')\n",
    "#test_simhash = pd.read_csv('test_feature_simhash.csv')\n",
    "test_tfidf = pd.read_csv('data/test_feature_tfidf.csv')\n",
    "\n",
    "test_graph_clique = pd.read_csv('data/test_feature_graph_clique.csv')\n",
    "test_graph_pagerank = pd.read_csv('data/test_feature_graph_pagerank.csv')\n",
    "test_graph_freq = pd.read_csv('data/test_feature_graph_question_freq.csv')\n",
    "test_graph_intersect = pd.read_csv('data/test_feature_graph_intersect.csv')\n",
    "\n",
    "X_test = pd.concat([\n",
    "        test_difflib,\n",
    "        test_embedding,\n",
    "        test_embedding2,\n",
    "        test_fuzz,\n",
    "        test_len,\n",
    "        #test_match,\n",
    "        test_match_2,\n",
    "        #test_oof,\n",
    "        #test_simhash,\n",
    "        test_tfidf,\n",
    "        test_graph_clique,\n",
    "        test_graph_pagerank,\n",
    "        test_graph_freq,\n",
    "        test_graph_intersect,\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((404290, 77), (2345796, 77))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(404290, 77)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('lxy_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('lxy_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cur = pd.read_csv('lxy_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cur.to_csv('hello.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_cur = pd.read_csv('hello.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2345796, 74)"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "now_cur.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UpDown Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.18975293212164862\n"
     ]
    }
   ],
   "source": [
    "#UPDownSampling\n",
    "pos_train = X_train[y_train == 1]\n",
    "neg_train = X_train[y_train == 0]\n",
    "X_train = pd.concat((neg_train, pos_train.iloc[:int(0.8*len(pos_train))], neg_train))\n",
    "y_train = np.array([0] * neg_train.shape[0] + [1] * pos_train.iloc[:int(0.8*len(pos_train))].shape[0] + [0] * neg_train.shape[0])\n",
    "print(np.mean(y_train))\n",
    "del pos_train, neg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.18923467767545252\n"
     ]
    }
   ],
   "source": [
    "pos_valid = X_valid[y_valid == 1]\n",
    "neg_valid = X_valid[y_valid == 0]\n",
    "X_valid = pd.concat((neg_valid, pos_valid.iloc[:int(0.8 * len(pos_valid))], neg_valid))\n",
    "y_valid = np.array([0] * neg_valid.shape[0] + [1] * pos_valid.iloc[:int(0.8 * len(pos_valid))].shape[0] + [0] * neg_valid.shape[0])\n",
    "print(np.mean(y_valid))\n",
    "del pos_valid, neg_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lots of XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training for fold = 1\n",
      "[0]\ttrain-logloss:0.70918\tvalid-logloss:0.70796\n",
      "[50]\ttrain-logloss:0.33497\tvalid-logloss:0.33727\n",
      "[100]\ttrain-logloss:0.27479\tvalid-logloss:0.27899\n",
      "[150]\ttrain-logloss:0.25728\tvalid-logloss:0.26268\n",
      "[200]\ttrain-logloss:0.24903\tvalid-logloss:0.25553\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-18e384b803ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'training for fold = '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'-> predicting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0md_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lianxinyu/opt/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    233\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lianxinyu/opt/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lianxinyu/opt/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1280\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    np.random.seed(i+1)\n",
    "    params = {}\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    et = [.02,.025,.01,.015]\n",
    "    params['eta'] = np.random.choice(et)\n",
    "    params['n_jobs'] = 5\n",
    "    depth = [4,5,6,7]\n",
    "    params['max_depth'] = np.random.choice(depth)\n",
    "    sub = [.5,.6,.7,.4]\n",
    "    params['subsample'] = np.random.choice(sub)\n",
    "    params['base_score'] = 0.2\n",
    "    col = [1,.7]\n",
    "    params['colsample_bytree'] = np.random.choice(col)\n",
    "    #params['scale_pos_weight'] = 0.36\n",
    "\n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    print ('training for fold = '+ str(i+1))\n",
    "    bst = xgb.train(params, d_train, 1000, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "    print ('-> predicting')\n",
    "    d_test = xgb.DMatrix(X_test)\n",
    "    p_test = bst.predict(d_test, ntree_limit=bst.best_ntree_limit)\n",
    "    print('saving to csv')\n",
    "    sub = pd.read_csv('xgb_final.csv')\n",
    "    sub[str('fold'+ str(i+1))] = p_test\n",
    "    sub.to_csv('xgb_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    params = {}\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    params['eta'] = 0.02\n",
    "    params['n_jobs'] = 5\n",
    "    params['max_depth'] = 6\n",
    "    params['subsample'] = 0.6\n",
    "    params['base_score'] = 0.2\n",
    "    #params['scale_pos_weight'] = 0.36\n",
    "\n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0]\ttrain-logloss:0.70918\tvalid-logloss:0.70796\n",
      "[50]\ttrain-logloss:0.33497\tvalid-logloss:0.33727\n",
      "[100]\ttrain-logloss:0.27479\tvalid-logloss:0.27899\n",
      "[150]\ttrain-logloss:0.25728\tvalid-logloss:0.26268\n",
      "[200]\ttrain-logloss:0.24903\tvalid-logloss:0.25553\n",
      "[250]\ttrain-logloss:0.24304\tvalid-logloss:0.25124\n",
      "[300]\ttrain-logloss:0.23830\tvalid-logloss:0.24824\n",
      "[350]\ttrain-logloss:0.23421\tvalid-logloss:0.24601\n",
      "[400]\ttrain-logloss:0.23054\tvalid-logloss:0.24408\n",
      "[450]\ttrain-logloss:0.22729\tvalid-logloss:0.24246\n",
      "[500]\ttrain-logloss:0.22470\tvalid-logloss:0.24118\n",
      "[550]\ttrain-logloss:0.22240\tvalid-logloss:0.24025\n",
      "[600]\ttrain-logloss:0.22010\tvalid-logloss:0.23937\n",
      "[650]\ttrain-logloss:0.21808\tvalid-logloss:0.23876\n",
      "[700]\ttrain-logloss:0.21596\tvalid-logloss:0.23811\n",
      "[750]\ttrain-logloss:0.21385\tvalid-logloss:0.23751\n",
      "[800]\ttrain-logloss:0.21200\tvalid-logloss:0.23710\n",
      "[850]\ttrain-logloss:0.20999\tvalid-logloss:0.23649\n",
      "[900]\ttrain-logloss:0.20824\tvalid-logloss:0.23609\n",
      "[950]\ttrain-logloss:0.20643\tvalid-logloss:0.23575\n",
      "[1000]\ttrain-logloss:0.20466\tvalid-logloss:0.23540\n",
      "[1050]\ttrain-logloss:0.20294\tvalid-logloss:0.23512\n",
      "[1100]\ttrain-logloss:0.20147\tvalid-logloss:0.23493\n",
      "[1150]\ttrain-logloss:0.19987\tvalid-logloss:0.23469\n",
      "[1200]\ttrain-logloss:0.19828\tvalid-logloss:0.23448\n",
      "[1250]\ttrain-logloss:0.19672\tvalid-logloss:0.23434\n",
      "[1300]\ttrain-logloss:0.19506\tvalid-logloss:0.23411\n",
      "[1350]\ttrain-logloss:0.19355\tvalid-logloss:0.23390\n",
      "[1400]\ttrain-logloss:0.19205\tvalid-logloss:0.23371\n",
      "[1450]\ttrain-logloss:0.19065\tvalid-logloss:0.23361\n",
      "[1499]\ttrain-logloss:0.18931\tvalid-logloss:0.23347\n",
      "0.23347579016421527\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(params, d_train, 1500, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "print(log_loss(y_valid, bst.predict(d_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'xgboost' from '/Users/lianxinyu/opt/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/__init__.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can't pickle module objects",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8148b44e6798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xgb.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/lianxinyu/opt/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lianxinyu/opt/anaconda3/envs/ml/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lianxinyu/opt/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lianxinyu/opt/anaconda3/envs/ml/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle module objects"
     ]
    }
   ],
   "source": [
    "\n",
    "#save model\n",
    "joblib.dump(xgb, 'xgb.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['diff_ratios', 'google_news_wmd', 'google_news_norm_wmd', 'google_news_cosine_distance', 'google_news_cityblock_distance', 'google_news_jaccard_distance', 'google_news_canberra_distance', 'google_news_euclidean_distance', 'google_news_minkowski_distance', 'google_news_braycurtis_distance', 'google_news_skew_q1vec', 'google_news_skew_q2vec', 'google_news_kur_q1vec', 'google_news_kur_q2vec', 'fuzz_qratio', 'fuzz_WRatio', 'fuzz_partial_ratio', 'fuzz_partial_token_set_ratio', 'fuzz_partial_token_sort_ratio', 'fuzz_token_set_ratio', 'fuzz_token_sort_ratio', 'char_len1', 'char_len2', 'word_len1', 'word_len2', 'char_len_diff_ratio', 'word_len_diff_ratio', 'word_match_ratio_2', 'word_match_ratio_2_root', 'tfidf_word_match_ratio_2', 'shared_count_2', 'stops1_ratio', 'stops2_ratio', 'shared_2gram', 'word_match_cosine', 'words_hamming', 'diff_stops_r', 'caps_count_q1', 'caps_count_q2', 'diff_caps', 'avg_world_len1', 'avg_world_len2', 'diff_avg_word', 'q1_how', 'q2_how', 'how_both', 'q1_what', 'q2_what', 'what_both', 'q1_which', 'q2_which', 'which_both', 'q1_who', 'q2_who', 'who_both', 'q1_where', 'q2_where', 'where_both', 'q1_when', 'q2_when', 'when_both', 'q1_why', 'q2_why', 'why_both', 'tfidf_sum1', 'tfidf_sum2', 'tfidf_mean1', 'tfidf_mean2', 'tfidf_len1', 'tfidf_len2', 'graph_clique_feat', 'q1_pr', 'q2_pr', 'q1_freq', 'q2_freq', 'q1_q2_intersect', 'q1_q2_wm_ratio']\n",
    "['diff_ratios', 'google_news_wmd', 'google_news_norm_wmd', 'google_news_cosine_distance', 'google_news_cityblock_distance', 'google_news_jaccard_distance', 'google_news_canberra_distance', 'google_news_euclidean_distance', 'google_news_minkowski_distance', 'google_news_braycurtis_distance', 'fuzz_qratio', 'fuzz_WRatio', 'fuzz_partial_ratio', 'fuzz_partial_token_set_ratio', 'fuzz_partial_token_sort_ratio', 'fuzz_token_set_ratio', 'fuzz_token_sort_ratio', 'char_len1', 'char_len2', 'word_len1', 'word_len2', 'char_len_diff_ratio', 'word_len_diff_ratio', 'word_match_ratio_2', 'word_match_ratio_2_root', 'tfidf_word_match_ratio_2', 'shared_count_2', 'stops1_ratio', 'stops2_ratio', 'shared_2gram', 'word_match_cosine', 'words_hamming', 'diff_stops_r', 'caps_count_q1', 'caps_count_q2', 'diff_caps', 'avg_world_len1', 'avg_world_len2', 'diff_avg_word', 'q1_how', 'q2_how', 'how_both', 'q1_what', 'q2_what', 'what_both', 'q1_which', 'q2_which', 'which_both', 'q1_who', 'q2_who', 'who_both', 'q1_where', 'q2_where', 'where_both', 'q1_when', 'q2_when', 'when_both', 'q1_why', 'q2_why', 'why_both', 'tfidf_sum1', 'tfidf_sum2', 'tfidf_mean1', 'tfidf_mean2', 'tfidf_len1', 'tfidf_len2', 'graph_clique_feat', 'q1_pr', 'q2_pr', 'q1_freq', 'q2_freq', 'q1_q2_intersect', 'q1_q2_wm_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(X_test)\n",
    "p_test = bst.predict(d_test, ntree_limit=bst.best_ntree_limit)\n",
    "sub = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = [i for i in range(2345796)]\n",
    "sub['test_id'] = test_ids\n",
    "sub['is_duplicate'] = p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.000589\n",
       "1        1      0.124254\n",
       "2        2      0.183836\n",
       "3        3      0.001145\n",
       "4        4      0.121627"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_id</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.000589</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.124254</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.183836</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.001145</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.121627</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub.to_csv('sub_xgb_6.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can't pickle module objects",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e124b3efc320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle module objects"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file_name = \"xgb.pkl\"\n",
    "\n",
    "# save\n",
    "pickle.dump(xgb, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'xgboost' from '/Users/lianxinyu/opt/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/__init__.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can't pickle module objects",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8a81a2c67228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pima.pickle.dat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle module objects"
     ]
    }
   ],
   "source": [
    "pickle.dump(xgb, open(\"pima.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python379jvsc74a57bd005a34060156012a9cd9180a4b5442552877c3ff4849eab2334de1908f6411db0",
   "display_name": "Python 3.7.9 64-bit ('ml': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}